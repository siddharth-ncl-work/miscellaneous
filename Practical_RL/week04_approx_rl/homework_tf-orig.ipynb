{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Network implementation\n",
    "\n",
    "This notebook shamelessly demands you to implement a DQN - an approximate q-learning algorithm with experience replay and target networks - and see if it works any better this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    %tensorflow_version 1.x\n",
    "    \n",
    "    if not os.path.exists('.setup_complete'):\n",
    "        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
    "\n",
    "        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/framebuffer.py\n",
    "        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/replay_buffer.py\n",
    "        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/atari_wrappers.py\n",
    "        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/utils.py\n",
    "\n",
    "        !touch .setup_complete\n",
    "\n",
    "# This code creates a virtual display to draw game images on.\n",
    "# It will have no effect if your machine has a monitor.\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Frameworks__ - we'll accept this homework in any deep learning framework. This particular notebook was designed for tensorflow, but you will find it easy to adapt it to almost any python-based deep learning framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's play some old videogames\n",
    "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/nerd.png)\n",
    "\n",
    "This time we're gonna apply approximate q-learning to an Atari game called Breakout. It's not the hardest thing out there, but it's definitely way more complex than anything we tried before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"BreakoutNoFrameskip-v4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what observations look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6UAAAH3CAYAAABD+PmTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA9WElEQVR4nO3df5BddZ3n/9e7u5MsND+SGMEUJBDYCF8yOEGzWUtWvq4MgpQ1wS3HDbvlZHd1o1VQDlVMuTDWruhXqlRAa79Oqd9Y8G12vm6QXYyytTCYLztLtGZHCU7EBAgEjKZJkyABQxoS0t3v/aNPwiW5nT59zzn3c877Ph9Vt7rvuff2fcd+puWdvn3a3F0AAAAAAKTQl3oAAAAAAEDvYikFAAAAACTDUgoAAAAASIalFAAAAACQDEspAAAAACAZllIAAAAAQDKVLaVmdpWZbTezHWZ2U1XPA6RA34iOxhEdjSMy+kbTWBW/p9TM+iU9LekKScOSHpV0rbs/UfqTAV1G34iOxhEdjSMy+kYTVfWd0pWSdrj7c+7+hqR7JK2q6LmAbqNvREfjiI7GERl9o3EGKvq4Z0na1XJ9WNI/br2Dma2VtDa7+p6K5gBa/c7d317Cx5m2b4nGkQSNI7quNU7fSICv4YhuysarWkqtzbG3vE7Y3ddJWidJZlb+a4iB4/2mpI8zbd8SjSMJGkd0XWucvpEAX8MR3ZSNV/Xy3WFJi1quny1pd0XPBXQbfSM6Gkd0NI7I6BuNU9V3Sh+VtNTMlkh6XtJqSf+ioucqTX9/v0466aTc9x8dHVXriaIGBwdl1u4fp453+PBhHTp06Oj1OXPmaNasWbmf+8CBA7nvO52TTz5ZfX35/n1iYmJCr732WmnPfaxTTjmla89VQCP7lmg8DxqXROO5Hkvj7dF4deh7evQtqaF9SzSeR9TGK1lK3X3MzK6X9JCkfkl3ufu2Kp6rTBdccIE+9alP5b7/Lbfcov379x+9/sUvfjF3UI8++qjWr19/9PpHPvIRXXrppbke6+668cYbc885nc9+9rM644wzct133759+vKXv1zac7eaNWuWvvSlLx29PjIyottuu62S5yqiqX1LNJ4HjdM4jXeOxqtF39Oj7+b2LdF4HlEbr+o7pXL3ByQ9UNXH74bR0VGNjo4evT537lzNnj0712PdXS+++OLR6wMDA5o/f37u53755Zd1+PDho9cXLFiQ+y9ZUS+++OJb/tWpVetf/F4WoW+Jxtuh8Uk0TuPRRWicvo9H35Mi9C3ReDtRG69sKY1g06ZN2rhx49Hra9eu1YUXXpjrsYcPH9ZXvvKVo9ff8Y536HOf+1zu5x4aGtKuXW+eOO3WW2+d0csZirjttts0NjbWledCWjSO6GgckdE3oqPx3sFSiuOcc845Gh8fb3vb2NiYhoeHuzwRUC4aR3Q0jsjoG9H1YuMspTjOddddN+VtVb6OHegWGkd0NI7I6BvR9WLjLKXQ9u3b9cILL7S9zcx08cUXd3kioFw0juhoHJHRN6KjcZZSSNqwYcOUt/X19en222/v4jRA+Wgc0dE4IqNvREfjLKUntHjxYr3vfe87en3u3Lm5H9vX1/eWx5522mkzeu53vetdWrTozd973N/fP6PHz8Qll1wy5Q9u5/1dT2gmGqfx6GicxiOjb/qOjsZ7p3GW0hNYtmyZli1b1tFjBwYG9LGPfazj57788ss7fuxMXXnllbl/NxJioXFER+OIjL4RHY33DpbSFnv37tWDDz6Y+/6HDh16y/WHHnoo92NHRkbecn3btm3Jfu/QT37yE5188sm57nvw4MHK5hgfH3/L//4HDhyo7Ll6FY1Pj8abjcanR+PNRd/To+9mo/HpRW3cpvrFrN1kZumHQC94zN1XpHhiGkeX0DiiS9I4faNL+BqO6KZsvBbfKZ03b56uuOKK1GMguHvvvTfZc9M4uoHGEV2qxukb3cDXcER3osZrsZQODg7qve99b+oxEFzKL/Y0jm6gcUSXqnH6RjfwNRzRnajxvi7OAQAAAADAW7CUAgAAAACSYSkFAAAAACTDUgoAAAAASKbjpdTMFpnZ35jZk2a2zcz+LDt+i5k9b2ZbssvV5Y0LdA+NIzoaR2T0jehoHJEUOfvumKQb3f0XZnaqpMfMbGN22zfc/fbi4wFJ0Tiio3FERt+IjsYRRsdLqbuPSBrJ3n/VzJ6UdFZZgwGp0Tiio3FERt+IjsYRSSk/U2pm50q6RNLPskPXm9njZnaXmc2b4jFrzWyzmW0eHR0tYwygMjSO6GgckdE3oqNxNF3hpdTMTpF0n6Qb3H2/pG9LOl/Sck3+680d7R7n7uvcfYW7rxgcHCw6BlAZGkd0NI7I6BvR0TgiKLSUmtksTf4l+J67/0CS3H2Pu4+7+4Sk70paWXxMIA0aR3Q0jsjoG9HROKIocvZdk3SnpCfd/estxxe23O2jkrZ2Ph6QDo0jOhpHZPSN6GgckRQ5++6lkj4h6VdmtiU79heSrjWz5ZJc0k5Jny7wHEBKNI7oaByR0Teio3GEUeTsuz+VZG1ueqDzcdo+jyYmJsr8kAiqr69Pk/9oWA4aR93QOKIrs3H6Rt3wNRzRFWm8yHdKu2Lnzp365je/mXoMNMANN9ygxYsXpx5jxmgcedE4omti4/SNvJrYt0TjyK9I46X8ShgAAAAAADrBUgoAAAAASIalFAAAAACQDEspAAAAACAZllIAAAAAQDIspQAAAACAZFhKAQAAAADJsJQCAAAAAJJhKQUAAAAAJMNSCgAAAABIhqUUAAAAAJAMSykAAAAAIBmWUgAAAABAMiylAAAAAIBkBoo82Mx2SnpV0rikMXdfYWbzJX1f0rmSdkr6uLu/XGxMIA0aR3Q0juhoHJHRN6Io4zul/9Tdl7v7iuz6TZIedvelkh7OrgNNRuOIjsYRHY0jMvpG41Xx8t1Vku7O3r9b0jUVPAeQEo0jOhpHdDSOyOgbjVN0KXVJPzazx8xsbXbsTHcfkaTs7RntHmhma81ss5ltHh0dLTgGUBkaR3Q0jug6apy+0RB8DUcIhX6mVNKl7r7bzM6QtNHMnsr7QHdfJ2mdJC1atMgLzgFUhcYRHY0juo4ap280BF/DEUKh75S6++7s7V5JGyStlLTHzBZKUvZ2b9EhgVRoHNHROKKjcURG34ii46XUzAbN7NQj70v6kKStku6XtCa72xpJPyo6JJACjSM6Gkd0NI7I6BuRFHn57pmSNpjZkY/zn939r83sUUn3mtknJf1W0p8UHxNIgsYRHY0jOhpHZPSNMDpeSt39OUl/2Ob4S5IuLzIUUAc0juhoHNHROCKjb0RS9ERHlbt47lxtuuKK1GOgAZ44/XS9lnqIDtA48qJxRNfExukbeTWxb4nGkV+Rxmu/lJqk2f39qcdAA1TxS3e7gcaRF40juiY2Tt/Iq4l9SzSO/Io03tS/HwAAAACAAFhKAQAAAADJsJQCAAAAAJKp/c+UyiQ3Tz0FUB0aR3Q0jsjoG9HROLqg9kup/4Nx+fmvph4DDeBzxlOP0BEaR140juia2Dh9I68m9i3ROPIr0jgv3wUAAAAAJMNSCgAAAABIhqUUAAAAAJAMSykAAAAAIJnan+hIkg73N/MHw9Fdbqkn6ByNIw8aR3RNbZy+kUdT+5ZoHPkUabz2S+lY/4ReHTyUegw0wHjfROoROkLjyIvGEV0TG6dv5NXEviUaR35FGufluwAAAACAZFhKAQAAAADJdPzyXTO7QNL3Ww6dJ+k/SJor6d9KejE7/hfu/kCnzwOkQuOIjsYRHY0jMvpGJB0vpe6+XdJySTKzfknPS9og6V9L+oa7317GgEAqNI7oaBzR0Tgio29EUtaJji6X9Ky7/8as3FOLTcxyvbZgrNSPiZgm5FV+eBpHcjSO6JrYOH0jryb2LdE48ivSeFlL6WpJ61uuX29mfypps6Qb3f3lTj/wxIDr4Nxmnq0M3eWvSKruayaNIzkaR3RNbJy+kVcT+5ZoHPkVabzwiY7MbLakP5b0X7JD35Z0viZfTjAi6Y4pHrfWzDab2ebR0dGiYwCVoXFER+OIrpPG6RtNwddwRFDG2Xc/LOkX7r5Hktx9j7uPu/uEpO9KWtnuQe6+zt1XuPuKwcHBEsYAKkPjiI7GEd2MG6dvNAhfw9F4ZSyl16rl5QJmtrDlto9K2lrCcwAp0Tiio3FER+OIjL7ReIV+ptTMTpZ0haRPtxz+mpktl+SSdh5zG9AoNI7oaBzR0Tgio29EUWgpdffXJL3tmGOfKDTRMV7RbP1s4swyPySCutBnqewXn9A46oTGEV0TG6dv5NXEviUaR35FGi/r7LuVOSzTS5qTegw0wJjKPQV6t9A48qJxRNfExukbeTWxb4nGkV+Rxsv4mVIAAAAAADrCUgoAAAAASIalFAAAAACQDEspAAAAACCZ2p/oyH+3SG/89ZWpx0AD+Mpt0mmjqceYMRpHXjSO6JrYOH0jryb2LdE48ivSeO2XUrlJE/UfEzXgzTyrHY0jNxpHdE1snL6RVxP7lmgc+RVonJfvAgAAAACSYSkFAAAAACTDUgoAAAAASKb2LxB3TWh8/GDqMdAA7hOpR+gIjSMvGkd0TWycvpFXE/uWaBz5FWm89kvp/le26pGNn049BhrgkmU3aN7cxanHmDEaR140juia2Dh9I68m9i3ROPIr0jgv3wUAAAAAJMNSCgAAAABIhqUUAAAAAJDMtEupmd1lZnvNbGvLsflmttHMnsnezmu57WYz22Fm283syqoGB8pC44iOxhEZfSM6GkcvyPOd0iFJVx1z7CZJD7v7UkkPZ9dlZhdJWi1pWfaYb5lZf2nTAtUYEo0jtiHROOIaEn0jtiHROIKbdil1902S9h1zeJWku7P375Z0Tcvxe9z9kLv/WtIOSSvLGRWoBo0jOhpHZPSN6GgcvaDTnyk9091HJCl7e0Z2/CxJu1ruN5wdA5qGxhEdjSMy+kZ0NI5Qyj7RkbU55m3vaLbWzDab2ebR0dGSxwAqQ+OIjsYRGX0jOhpHI3W6lO4xs4WSlL3dmx0flrSo5X5nS9rd7gO4+zp3X+HuKwYHBzscA6gMjSM6Gkdk9I3oaByhdLqU3i9pTfb+Gkk/ajm+2szmmNkSSUsl/bzYiEASNI7oaByR0Teio3GEMjDdHcxsvaQPSFpgZsOSviDpK5LuNbNPSvqtpD+RJHffZmb3SnpC0pik69x9vKLZgVLQOKKjcURG34iOxtELpl1K3f3aKW66fIr73yrp1iJDAd1E44iOxhEZfSM6GkcvKPtERwAAAAAA5MZSCgAAAABIhqUUAAAAAJAMSykAAAAAIBmWUgAAAABAMiylAAAAAIBkWEoBAAAAAMmwlAIAAAAAkmEpBQAAAAAkw1IKAAAAAEiGpRQAAAAAkAxLKQAAAAAgGZZSAAAAAEAyLKUAAAAAgGRYSgEAAAAAyUy7lJrZXWa218y2thy7zcyeMrPHzWyDmc3Njp9rZq+b2Zbs8p0KZwdKQeOIjsYRGX0jOhpHL8jzndIhSVcdc2yjpD9w93dJelrSzS23Pevuy7PLZ8oZE6jUkGgcsQ2JxhHXkOgbsQ2JxhHctEupu2+StO+YYz9297Hs6t9JOruC2YCuoHFER+OIjL4RHY2jF5TxM6X/RtKDLdeXmNnfm9kjZvb+Ej4+kBqNIzoaR2T0jehoHI03UOTBZvZ5SWOSvpcdGpG02N1fMrP3SPqhmS1z9/1tHrtW0lpJmjdvXpExgMrQOKKjcURG34iOxhFFx98pNbM1kj4i6V+6u0uSux9y95ey9x+T9Kykd7Z7vLuvc/cV7r5icHCw0zGAytA4oqNxREbfiI7GEUlHS6mZXSXp30n6Y3d/reX4282sP3v/PElLJT1XxqBAN9E4oqNxREbfiI7GEc20L981s/WSPiBpgZkNS/qCJs/wNUfSRjOTpL/Lzu51maQvmdmYpHFJn3H3fW0/MFATNI7oaByR0Teio3H0gmmXUne/ts3hO6e4732S7is6FNBNNI7oaByR0Teio3H0gjLOvgsAAAAAQEdYSgEAAAAAybCUAgAAAACSYSkFAAAAACTDUgoAAAAASIalFAAAAACQDEspAAAAACAZllIAAAAAQDIspQAAAACAZFhKAQAAAADJsJQCAAAAAJJhKQUAAAAAJMNSCgAAAABIhqUUAAAAAJAMSykAAAAAIBmWUgAAAABAMtMupWZ2l5ntNbOtLcduMbPnzWxLdrm65babzWyHmW03syurGhwoC40jOhpHZPSN6GgcvSDPd0qHJF3V5vg33H15dnlAkszsIkmrJS3LHvMtM+sva1igIkOiccQ2JBpHXEOib8Q2JBpHcNMupe6+SdK+nB9vlaR73P2Qu/9a0g5JKwvMB1SOxhEdjSMy+kZ0NI5eUORnSq83s8ezlxTMy46dJWlXy32Gs2PHMbO1ZrbZzDaPjo4WGAOoDI0jOhpHZPSN6GgcYXS6lH5b0vmSlksakXRHdtza3NfbfQB3X+fuK9x9xeDgYIdjAJWhcURH44iMvhEdjSOUjpZSd9/j7uPuPiHpu3rzZQHDkha13PVsSbuLjQh0H40jOhpHZPSN6Ggc0XS0lJrZwparH5V05Gxg90tabWZzzGyJpKWSfl5sRKD7aBzR0Tgio29ER+OIZmC6O5jZekkfkLTAzIYlfUHSB8xsuSZfDrBT0qclyd23mdm9kp6QNCbpOncfr2RyoCQ0juhoHJHRN6KjcfSCaZdSd7+2zeE7T3D/WyXdWmQooJtoHNHROCKjb0RH4+gFRc6+CwAAAABAISylAAAAAIBkWEoBAAAAAMmwlAIAAAAAkmEpBQAAAAAkw1IKAAAAAEiGpRQAAAAAkAxLKQAAAAAgGZZSAAAAAEAyLKUAAAAAgGRYSgEAAAAAybCUAgAAAACSYSkFAAAAACTDUgoAAAAASIalFAAAAACQzLRLqZndZWZ7zWxry7Hvm9mW7LLTzLZkx881s9dbbvtOhbMDpaBxREfjiIy+ER2NoxcM5LjPkKS/lPSfjhxw939+5H0zu0PS71vu/6y7Ly9pPqAbhkTjiG1INI64hkTfiG1INI7gpl1K3X2TmZ3b7jYzM0kfl/TBkucCuobGER2NIzL6RnQ0jl5Q9GdK3y9pj7s/03JsiZn9vZk9Ymbvn+qBZrbWzDab2ebR0dGCYwCVoXFER+OIjL4RHY0jhDwv3z2RayWtb7k+Immxu79kZu+R9EMzW+bu+499oLuvk7ROkhYtWuQF5wCqQuOIjsYRGX0jOhpHCB1/p9TMBiT9M0nfP3LM3Q+5+0vZ+49JelbSO4sOCaRA44iOxhEZfSM6GkckRV6++0eSnnL34SMHzOztZtafvX+epKWSnis2IpAMjSM6Gkdk9I3oaBxh5PmVMOsl/S9JF5jZsJl9Mrtptd76cgFJukzS42b2S0n/VdJn3H1fmQMDZaNxREfjiIy+ER2NoxfkOfvutVMc/1dtjt0n6b7iYwHdQ+OIjsYRGX0jOhpHLyh69l0AAAAAADrGUgoAAAAASIalFAAAAACQDEspAAAAACAZllIAAAAAQDIspQAAAACAZKb9lTDdMG7Svv7xtrft75vo8jS95R+eeqpO6u/v6LGjY2N67sCBkifq3OCrr+rUV15JPUZbNJ4OjXcHjadD49Wj73r4P04/XQNmHT32pUOHtPv110ueaGbq2rdE43Vw4WmnaVZfZ98vfOWNN7TrtddKnmjmijRei6X0QN+E/vbU9l8oXjn5YJen6S3//uKLdcFpp3X02MdeeknXPfpoyRN17vwnntBFzz+feoy2aDwdGu8OGk+HxqtH3/Xw9fe8R/Nmz+7osT/47W/1tSeeKHmimalr3xKN18FXL7lEZ550UkePfWj3bn3h8cdLnmjmijTOy3cBAAAAAMmwlAIAAAAAkqnFy3eRzv944QVt7fC137tGR8sdBqgAjSM6Gkev+O/DwzppoLP/dN3y8sslTwOU68Hdu3XqrFkdPfbJ3/++5Gm6j6W0x9393HOpRwAqReOIjsbRK/7y6adTjwBU5jvPPJN6hKRYShHGhl279NO9e1OPAVSGxhEdjSMy+kZ0RRqvxVJ6cN/v9fT6B9ve9sYr+7s8DZrqvw0Ppx5hSjSOMtA4oqtr4/SNMtS1b4nGUY4ijZu7lzhKh0OYpR8CveAxd1+R4olpHF1C44guSeP0jS7haziim7Lxac++a2aLzOxvzOxJM9tmZn+WHZ9vZhvN7Jns7byWx9xsZjvMbLuZXVnenwMoH40jMvpGdDSO6GgcPcHdT3iRtFDSu7P3T5X0tKSLJH1N0k3Z8ZskfTV7/yJJv5Q0R9ISSc9K6p/mOZwLly5cNtM4l+CX4xpXF/qmcS5dvCRpvAZ/bi69ceG/U7hEv7Rt3N2n/06pu4+4+y+y91+V9KSksyStknR3dre7JV2Tvb9K0j3ufsjdfy1ph6SV0z0PkAqNIzL6RnQ0juhoHL1g2qW0lZmdK+kSST+TdKa7j0iTf1kknZHd7SxJu1oeNpwdO/ZjrTWzzWa2uYO5gUrQOCIrs+/s49E4aoWv4YiOxhFV7rPvmtkpku6TdIO77zezKe/a5pgfd8B9naR12cc+7nag22gckZXdt0TjqBe+hiM6Gkdkub5TamazNPmX4Hvu/oPs8B4zW5jdvlDSkV9KMyxpUcvDz5a0u5xxgWrQOCKjb0RH44iOxhFdnrPvmqQ7JT3p7l9vuel+SWuy99dI+lHL8dVmNsfMlkhaKunn5Y0MlIvGERl9IzoaR3Q0jp6Q44yK/0ST3/J/XNKW7HK1pLdJeljSM9nb+S2P+bwmz/S1XdKHOWsjl5pcpjqrHY1ziXJpd2bSyvumcS5dvCRpvAZ/bi69ceG/U7hEv0x59l3LQkyK17GjS/il1IiOxhFdksbpG13C13BEN2XjMzr7LgAAAAAAZWIpBQAAAAAkw1IKAAAAAEgm9+8prdjvJI1mb5tqgZg/pTzzn9ONQaZA4+n1wvwpGz+gyRNqNFUv9FF3dW6cr+Hp9cL8/HdKMb3QSJ0VarwWJzqSJDPbnOqHu8vA/Gk1Yf4mzHgizJ9W3eev+3zTYf706v5nqPt802H+tJowfxNmPBHmT6vo/Lx8FwAAAACQDEspAAAAACCZOi2l61IPUBDzp9WE+Zsw44kwf1p1n7/u802H+dOr+5+h7vNNh/nTasL8TZjxRJg/rULz1+ZnSgEAAAAAvadO3ykFAAAAAPQYllIAAAAAQDLJl1Izu8rMtpvZDjO7KfU8eZjZTjP7lZltMbPN2bH5ZrbRzJ7J3s5LPWcrM7vLzPaa2daWY1PObGY3Z5+T7WZ2ZZqp3zTF/LeY2fPZ52GLmV3dcltt5qfx6tF3WjRePRpPh767g8bTofHqNb1vqQuNu3uyi6R+Sc9KOk/SbEm/lHRRyplyzr1T0oJjjn1N0k3Z+zdJ+mrqOY+Z7zJJ75a0dbqZJV2UfS7mSFqSfY76azj/LZL+vM19azM/jSftg767MzuNp2uExqufm77TNkLj1c9N4+n6aEzfJ/gzlNZ46u+UrpS0w92fc/c3JN0jaVXimTq1StLd2ft3S7om3SjHc/dNkvYdc3iqmVdJusfdD7n7ryXt0OTnKpkp5p9Knean8S6g76Tz03gX0Dhfw0tQ274lGheNl6G2jTe9b6n6xlMvpWdJ2tVyfTg7Vncu6cdm9piZrc2OnenuI5KUvT0j2XT5TTVzkz4v15vZ49lLCo687KFO89dplpmI0Dh9d0fd5smLxuuh7o3XaZaZiNC3ROPdUKdZZiJC4xH6lkpqPPVSam2ONeF31Fzq7u+W9GFJ15nZZakHKllTPi/flnS+pOWSRiTdkR2v0/x1mmUmIjfelM9JE/qW6jdPXjSeXhMar9MsMxG5b6k5nxcar07kxpv0OSmt8dRL6bCkRS3Xz5a0O9Esubn77uztXkkbNPnt6D1mtlCSsrd7002Y21QzN+Lz4u573H3c3SckfVdvviygTvPXaZbcgjRO391Rt3lyofH0GtJ4nWbJLUjfEo13Q51myS1I443uWyq38dRL6aOSlprZEjObLWm1pPsTz3RCZjZoZqceeV/ShyRt1eTca7K7rZH0ozQTzshUM98vabWZzTGzJZKWSvp5gvlO6Mhf5MxHNfl5kOo1P42nQ9/dQePp0Hj16DstGq8ejafT6L6lkhvvxtmaTnSRdLWkpzV5VqbPp54nx7znafJsUr+UtO3IzJLeJulhSc9kb+ennvWYuddr8tvqhzX5rxefPNHMkj6ffU62S/pwTef/K0m/kvR4Fv/COs5P48n6oO/uzU/jaRqh8e7MTt/pGqHx7sxO42n6aEzfJ/gzlNa4ZQ8CAAAAAKDrUr98FwAAAADQw1hKAQAAAADJsJQCAAAAAJJhKQUAAAAAJMNSCgAAAABIhqUUAAAAAJAMSykAAAAAIBmWUgAAAABAMiylAAAAAIBkWEoBAAAAAMmwlAIAAAAAkmEpBQAAAAAkw1IKAAAAAEiGpRQAAAAAkAxLKQAAAAAgGZZSAAAAAEAyLKUAAAAAgGRYSgEAAAAAybCUAgAAAACSYSkFAAAAACTDUgoAAAAASIalFAAAAACQDEspAAAAACAZllIAAAAAQDIspQAAAACAZFhKAQAAAADJsJQCAAAAAJJhKQUAAAAAJMNSCgAAAABIhqUUAAAAAJAMSykAAAAAIBmWUgAAAABAMiylAAAAAIBkWEoBAAAAAMmwlAIAAAAAkmEpBQAAAAAkw1IKAAAAAEiGpRQAAAAAkAxLKQAAAAAgGZZSAAAAAEAyLKUAAAAAgGRYSgEAAAAAybCUAgAAAACSYSkFAAAAACTDUgoAAAAASKaypdTMrjKz7Wa2w8xuqup5gBToG9HROKKjcURG32gac/fyP6hZv6SnJV0haVjSo5KudfcnSn8yoMvoG9HROKKjcURG32iiqr5TulLSDnd/zt3fkHSPpFUVPRfQbfSN6Ggc0dE4IqNvNM5ARR/3LEm7Wq4PS/rHrXcws7WS1mZX31PRHECr37n720v4ONP2LdE4kqBxRNe1xukbCfA1HNFN2XhVS6m1OfaW1wm7+zpJ6yTJzMp/DTFwvN+U9HGm7VuicSRB44iua43TNxLgaziim7Lxql6+OyxpUcv1syXtrui5gG6jb0RH44iOxhEZfaNxqvpO6aOSlprZEknPS1ot6V9U9Fyl6e/v10knnZT7/qOjo2o9UdTg4KDM2v3j1PEOHz6sQ4cOHb0+Z84czZo1K/dzHzhwIPd9p3PyySerry/fv09MTEzotddeK+25j3XKKad07bkKaGTfEo3nQeOSaDzXY2m8PRqvDn1Pj74lNbRvicbziNp4JUupu4+Z2fWSHpLUL+kud99WxXOV6YILLtCnPvWp3Pe/5ZZbtH///qPXv/jFL+YO6tFHH9X69euPXv/IRz6iSy+9NNdj3V033nhj7jmn89nPflZnnHFGrvvu27dPX/7yl0t77lazZs3Sl770paPXR0ZGdNttt1XyXEU0tW+JxvOgcRqn8c7ReLXoe3r03dy+JRrPI2rjVX2nVO7+gKQHqvr43TA6OqrR0dGj1+fOnavZs2fneqy768UXXzx6fWBgQPPnz8/93C+//LIOHz589PqCBQty/yUr6sUXX3zLvzq1av2L38si9C3ReDs0PonGaTy6CI3T9/Hoe1KEviUabydq45UtpRFs2rRJGzduPHp97dq1uvDCC3M99vDhw/rKV75y9Po73vEOfe5zn8v93ENDQ9q1680Tp916660zejlDEbfddpvGxsa68lxIi8YRHY0jMvpGdDTeO1hKcZxzzjlH4+PjbW8bGxvT8PBwlycCykXjiI7GERl9I7pebJylFMe57rrrprytytexA91C44iOxhEZfSO6XmycpRTavn27Xnjhhba3mZkuvvjiLk8ElIvGER2NIzL6RnQ0zlIKSRs2bJjytr6+Pt1+++1dnAYoH40jOhpHZPSN6GicpfSEFi9erPe9731Hr8+dOzf3Y/v6+t7y2NNOO21Gz/2ud71Lixa9+XuP+/v7Z/T4mbjkkkum/MHtvL/rCc1E4zQeHY3TeGT0Td/R0XjvNM5SegLLli3TsmXLOnrswMCAPvaxj3X83JdffnnHj52pK6+8MvfvRkIsNI7oaByR0Teio/HewVLaYu/evXrwwQdz3//QoUNvuf7QQw/lfuzIyMhbrm/bti3Z7x36yU9+opNPPjnXfQ8ePFjZHOPj42/53//AgQOVPVevovHp0Xiz0fj0aLy56Ht69N1sND69qI3bVL+YtZvMLP0Q6AWPufuKFE9M4+gSGkd0SRqnb3QJX8MR3ZSN1+I7pfPmzdMVV1yRegwEd++99yZ7bhpHN9A4okvVOH2jG/gajuhO1HgtltLBwUG9973vTT0Ggkv5xZ7G0Q00juhSNU7f6Aa+hiO6EzXe18U5AAAAAAB4C5ZSAAAAAEAyLKUAAAAAgGRYSgEAAAAAyXS8lJrZIjP7GzN70sy2mdmfZcdvMbPnzWxLdrm6vHGB7qFxREfjiIy+ER2NI5IiZ98dk3Sju//CzE6V9JiZbcxu+4a73158PCApGkd0NI7I6BvR0TjC6HgpdfcRSSPZ+6+a2ZOSziprMCA1Gkd0NI7I6BvR0TgiKeVnSs3sXEmXSPpZduh6M3vczO4ys3lTPGatmW02s82jo6NljAFUhsYRHY0jMvpGdDSOpiu8lJrZKZLuk3SDu++X9G1J50tarsl/vbmj3ePcfZ27r3D3FYODg0XHACpD44iOxhEZfSM6GkcEhZZSM5ulyb8E33P3H0iSu+9x93F3n5D0XUkri48JpEHjiI7GERl9IzoaRxRFzr5rku6U9KS7f73l+MKWu31U0tbOxwPSoXFER+OIjL4RHY0jkiJn371U0ick/crMtmTH/kLStWa2XJJL2inp0wWeA0iJxhEdjSMy+kZ0NI4wipx996eSrM1ND3Q+Ttvn0cTERJkfEkH19fVp8h8Ny0HjqBsaR3RlNk7fqBu+hiO6Io0X+U5pV+zcuVPf/OY3U4+BBrjhhhu0ePHi1GPMGI0jLxpHdE1snL6RVxP7lmgc+RVpvJRfCQMAAAAAQCdYSgEAAAAAybCUAgAAAACSYSkFAAAAACTDUgoAAAAASIalFAAAAACQDEspAAAAACAZllIAAAAAQDIspQAAAACAZFhKAQAAAADJsJQCAAAAAJJhKQUAAAAAJMNSCgAAAABIhqUUAAAAAJDMQJEHm9lOSa9KGpc05u4rzGy+pO9LOlfSTkkfd/eXi40JpEHjiI7GER2NIzL6RhRlfKf0n7r7cndfkV2/SdLD7r5U0sPZdaDJaBzR0Tiio3FERt9ovCpevrtK0t3Z+3dLuqaC5wBSonFER+OIjsYRGX2jcYoupS7px2b2mJmtzY6d6e4jkpS9PaPdA81srZltNrPNo6OjBccAKkPjiI7GEV1HjdM3GoKv4Qih0M+USrrU3Xeb2RmSNprZU3kf6O7rJK2TpEWLFnnBOYCq0Diio3FE11Hj9I2G4Gs4Qij0nVJ335293Stpg6SVkvaY2UJJyt7uLTokkAqNIzoaR3Q0jsjoG1F0vJSa2aCZnXrkfUkfkrRV0v2S1mR3WyPpR0WHBFKgcURH44iOxhEZfSOSIi/fPVPSBjM78nH+s7v/tZk9KuleM/ukpN9K+pPiYwJJ0Diio3FER+OIjL4RRsdLqbs/J+kP2xx/SdLlRYYC6oDGER2NIzoaR2T0jUiKnuiochfPnatNV1yRegw0wBOnn67XUg/RARpHXjSO6JrYOH0jryb2LdE48ivSeO2XUpM0u78/9RhogCp+6W430DjyonFE18TG6Rt5NbFvicaRX5HGm/r3AwAAAAAQAEspAAAAACAZllIAAAAAQDK1/5lSmeTmqacAqkPjiI7GERl9IzoaRxfUfin1fzAuP//V1GOgAXzOeOoROkLjyIvGEV0TG6dv5NXEviUaR35FGufluwAAAACAZFhKAQAAAADJsJQCAAAAAJJhKQUAAAAAJFP7Ex1J0uH+Zv5gOLrLLfUEnaNx5EHjiK6pjdM38mhq3xKNI58ijdd+KR3rn9Crg4dSj4EGGO+bSD1CR2gcedE4omti4/SNvJrYt0TjyK9I47x8FwAAAACQDEspAAAAACCZjl++a2YXSPp+y6HzJP0HSXMl/VtJL2bH/8LdH+j0eYBUaBzR0Tiio3FERt+IpOOl1N23S1ouSWbWL+l5SRsk/WtJ33D328sYEEiFxhEdjSM6Gkdk9I1IyjrR0eWSnnX335iVe2qxiVmu1xaMlfoxEdOEvMoPT+NIjsYRXRMbp2/k1cS+JRpHfkUaL2spXS1pfcv1683sTyVtlnSju7987APMbK2ktZI0b968KT/wxIDr4Nxmnq0M3eWvSKruayaNIzkaR3R1apy+UbY69S3ROMpXpPHCJzoys9mS/ljSf8kOfVvS+Zp8OcGIpDvaPc7d17n7CndfMTg4WHQMoDI0juhoHNF10jh9oyn4Go4Iyjj77ocl/cLd90iSu+9x93F3n5D0XUkrS3gOICUaR3Q0juhoHJHRNxqvjKX0WrW8XMDMFrbc9lFJW0t4DiAlGkd0NI7oaByR0Tcar9DPlJrZyZKukPTplsNfM7PlklzSzmNuAxqFxhEdjSM6Gkdk9I0oCi2l7v6apLcdc+wThSY6xiuarZ9NnFnmh0RQF/oslf0TETSOOqFxRNfExukbeTWxb4nGkV+Rxss6+25lDsv0kuakHgMNMKZyT4HeLTSOvGgc0TWxcfpGXk3sW6Jx5Fek8TJ+phQAAAAAgI6wlAIAAAAAkmEpBQAAAAAkw1IKAAAAAEim9ic68t8t0ht/fWXqMdAAvnKbdNpo6jFmjMaRF40juiY2Tt/Iq4l9SzSO/Io0XvulVG7SRP3HRA14M89qR+PIjcYRXRMbp2/k1cS+JRpHfgUa5+W7AAAAAIBkWEoBAAAAAMmwlAIAAAAAkqn9C8RdExofP5h6DDSA+0TqETpC48iLxhFdExunb+TVxL4lGkd+RRqv/VK6/5WtemTjp1OPgQa4ZNkNmjd3ceoxZozGkReNI7omNk7fyKuJfUs0jvyKNM7LdwEAAAAAybCUAgAAAACSYSkFAAAAACQz7VJqZneZ2V4z29pybL6ZbTSzZ7K381puu9nMdpjZdjO7sqrBgbLQOKKjcURG34iOxtEL8nyndEjSVcccu0nSw+6+VNLD2XWZ2UWSVktalj3mW2bWX9q0QDWGROOIbUg0jriGRN+IbUg0juCmXUrdfZOkfcccXiXp7uz9uyVd03L8Hnc/5O6/lrRD0spyRgWqQeOIjsYRGX0jOhpHL+j0Z0rPdPcRScrenpEdP0vSrpb7DWfHjmNma81ss5ltHh0d7XAMoDI0juhoHJHRN6KjcYRS9omOrM0xb3dHd1/n7ivcfcXg4GDJYwCVoXFER+OIjL4RHY2jkTpdSveY2UJJyt7uzY4PS1rUcr+zJe3ufDwgGRpHdDSOyOgb0dE4Qul0Kb1f0prs/TWSftRyfLWZzTGzJZKWSvp5sRGBJGgc0dE4IqNvREfjCGVgujuY2XpJH5C0wMyGJX1B0lck3Wtmn5T0W0l/Iknuvs3M7pX0hKQxSde5+3hFswOloHFER+OIjL4RHY2jF0y7lLr7tVPcdPkU979V0q1FhgK6icYRHY0jMvpGdDSOXlD2iY4AAAAAAMiNpRQAAAAAkAxLKQAAAAAgGZZSAAAAAEAyLKUAAAAAgGRYSgEAAAAAybCUAgAAAACSYSkFAAAAACTDUgoAAAAASIalFAAAAACQDEspAAAAACAZllIAAAAAQDIspQAAAACAZFhKAQAAAADJsJQCqKV+M/WbpR4DAAAAFZt2KTWzu8xsr5ltbTl2m5k9ZWaPm9kGM5ubHT/XzF43sy3Z5TsVzg6Ugsbr6acf+pD+5xVXpB4jBBqvrzl9fZrTx78PF0HfiI7G0Qvy/D/hkKSrjjm2UdIfuPu7JD0t6eaW25519+XZ5TPljAlUakg0jtiGROO10yfpkQ99SA9+8IOpR2m6IdF3bZ0yMKDBgYHUYzTdkGgcwU27lLr7Jkn7jjn2Y3cfy67+naSzK5gN6AoaR3Q0jsjou74GzPT//9Ef6QeXXZZ6lEaj8fqbN3u2Tp81K/UYjVbGa4b+jaQHW64vMbO/N7NHzOz9JXx8IDUaT2DPwYPa8/rrqcfoFTSOyOgb0dF4Qif19+vBD35Qf3XppalHabRCr6cws89LGpP0vezQiKTF7v6Smb1H0g/NbJm772/z2LWS1krSvHnziowBVIbG07nmkUdSj9ATaDwdl/Tb0VEdHB9PPUpY9I3oaBxRdPydUjNbI+kjkv6lu7skufshd38pe/8xSc9Keme7x7v7Ondf4e4rBgcHOx0DqAyNIzoaT8slffwnP9Gf/u3fph4lJPquh2f279dzBw6kHiMkGkckHX2n1MyukvTvJP2f7v5ay/G3S9rn7uNmdp6kpZKeK2VSoItoHNHROCKj73oYc9cn+EeXStB4fUy46/GXX9Yrb7yRepRGm3YpNbP1kj4gaYGZDUv6gibP8DVH0kab/D2Cf5ed3esySV8yszFJ45I+4+772n5goCZoHNHROCKjb0RH4/V2aGJCa3/2s9RjNN60S6m7X9vm8J1T3Pc+SfcVHQroJhpHdDSOyOgb0dE4egG/sRsAAAAAkAxLKQAAAAAgGZZSAAAAAEAyLKUAAAAAgGRYSgEAAAAAybCUAgAAAACSYSkFAAAAACTDUgoAAAAASIalFAAAAACQDEspAAAAACAZllIAAAAAQDIspQAAAACAZFhKAQAAAADJsJQCAAAAAJJhKQUAAAAAJDPtUmpmd5nZXjPb2nLsFjN73sy2ZJerW2672cx2mNl2M7uyqsGBstA4oqNxREbfiI7G0QvyfKd0SNJVbY5/w92XZ5cHJMnMLpK0WtKy7DHfMrP+soYFKjIkGkdsQ6JxxDUk+kZsQ6JxBDftUurumyTty/nxVkm6x90PufuvJe2QtLLAfEDlaBzR0Tgio29ER+PoBUV+pvR6M3s8e0nBvOzYWZJ2tdxnODsGNBGNIzoaR2T0jehoHGF0upR+W9L5kpZLGpF0R3bc2tzX230AM1trZpvNbPPo6GiHYwCVoXFER+OIjL4RHY0jlI6WUnff4+7j7j4h6bt682UBw5IWtdz1bEm7p/gY69x9hbuvGBwc7GQMoDI0juhoHJHRN6KjcUTT0VJqZgtbrn5U0pGzgd0vabWZzTGzJZKWSvp5sRGB7qNxREfjiIy+ER2NI5qB6e5gZuslfUDSAjMblvQFSR8ws+WafDnATkmfliR332Zm90p6QtKYpOvcfbySyYGS0Diio3FERt+IjsbRC6ZdSt392jaH7zzB/W+VdGuRoYBuonFER+OIjL4RHY2jFxQ5+y4AAAAAAIWwlAIAAAAAkmEpBQAAAAAkw1IKAAAAAEiGpRQAAAAAkAxLKQAAAAAgGZZSAAAAAEAyLKUAAAAAgGRYSgEAAAAAybCUAgAAAACSYSkFAAAAACTDUgoAAAAASIalFAAAAACQDEspAAAAACAZllIAAAAAQDLTLqVmdpeZ7TWzrS3Hvm9mW7LLTjPbkh0/18xeb7ntOxXODpSCxhEdjSMy+kZ0NI5eMJDjPkOS/lLSfzpywN3/+ZH3zewOSb9vuf+z7r68pPmAbhgSjSO2IdE44hoSfSO2IdE4gpt2KXX3TWZ2brvbzMwkfVzSB0ueC+gaGkd0NI7I6BvR0Th6QdGfKX2/pD3u/kzLsSVm9vdm9oiZvb/gxwdSo3FER+OIjL4RHY0jhDwv3z2RayWtb7k+Immxu79kZu+R9EMzW+bu+499oJmtlbRWkubNm1dwDKAyNI7oaByR0Teio3GE0PF3Ss1sQNI/k/T9I8fc/ZC7v5S9/5ikZyW9s93j3X2du69w9xWDg4OdjgFUhsYRHY0jMvpGdDSOSIq8fPePJD3l7sNHDpjZ282sP3v/PElLJT1XbEQgGRpHdDSOyOgb0dE4wsjzK2HWS/pfki4ws2Ez+2R202q99eUCknSZpMfN7JeS/qukz7j7vjIHBspG44iOxhEZfSM6GkcvyHP23WunOP6v2hy7T9J9xccCuofGER2NIzL6RnQ0jl5Q9Oy7AAAAAAB0jKUUAAAAAJAMSykAAAAAIBmWUgAAAABAMiylAAAAAIBkWEoBAAAAAMmwlAIAAAAAkpn295R2w7hJ+/rH2962v2+iy9P0nneeeqrm9Pd39Nj9hw/rN6OjJU/UmcFXX9Wpr7ySeoy2aDwtGq8ejadF49Wi7/pYdvrp6jPr6LEvHjyoFw4eLHmi/Orat0TjdfMHp58u67DzPa+/rr2HDpU8UT5FGq/FUnqgb0J/e+rrbW975eR0Xzx6xf/1h3+oc045paPH/nTvXv35L35R8kSdOf+JJ3TR88+nHqMtGk+LxqtH42nReLXouz7+73/0jzQ40Nl/vv5/zz2nv3z66ZInyq+ufUs0XjffWrlSszv8h8b/55ln9P8++2zJE+VTpHFevgsAAAAASIalFAAAAACQTC1evou0fjwyovlz5nT02GdffbXkaYDy0Tiio3H0ivuHhzW7r7Pvqfyqpj/PCRzrh8PD6u/wZ0qf+v3vS56mO1hKoTsTve4c6BYaR3Q0jl7xH596KvUIQOW+/uSTqUfoOpZShLFh1y79dO/e1GMAlaFxREfjiIy+EV2RxmuxlB7c93s9vf7Btre98cr+Lk+Dpvpvw8OpR5gSjaMMNI7o6to4faMMde1bonGUo1Dj7n7Ci6RFkv5G0pOStkn6s+z4fEkbJT2TvZ3X8pibJe2QtF3SlTmew7lw6cJlM41zCX45rnF1oW8a59LFS5LGa/Dn5tIbF/47hUv0S9vG3V15/kNjoaR3Z++fKulpSRdJ+pqkm7LjN0n6avb+RZJ+KWmOpCWSnpXUz18ELjW4TPXFnsa5RLm0+w/2yvumcS5dvCRpvAZ/bi69ceG/U7hEv0y5lE57+jJ3H3H3X2Tvv6rJf6U5S9IqSXdnd7tb0jXZ+6sk3ePuh9z915r8V5qV0z0PkAqNIzL6RnQ0juhoHL1gRufUNrNzJV0i6WeSznT3EWnyL4ukM7K7nSVpV8vDhrNjQO3ROCKjb0RH44iOxhFV7hMdmdkpku6TdIO777epf3dOuxu8zcdbK2lt3ucHqkbjiKzsvrOPSeOoDb6GIzoaR2S5vlNqZrM0+Zfge+7+g+zwHjNbmN2+UNKR8/8Oa/IHso84W9LuYz+mu69z9xXuvqLT4YGy0Dgiq6JvicZRH3wNR3Q0juimXUpt8p9h7pT0pLt/veWm+yWtyd5fI+lHLcdXm9kcM1siaamkn5c3MlAuGkdk9I3oaBzR0Th6Qo4zKv4TTX7L/3FJW7LL1ZLeJulhTZ6G+mFJ81se83lNnulru6QPc9ZGLjW5THVWOxrnEuXS7syklfdN41y6eEnSeA3+3Fx648J/p3CJfpny7LuWhZiUmaUfAr3gsVQvUaFxdAmNI7okjdM3uoSv4YhuysZndPZdAAAAAADKxFIKAAAAAEiGpRQAAAAAkAxLKQAAAAAgmYHUA2R+J2k0e9tUC8T8KeWZ/5xuDDIFGk+vF+ZP2fgBTZ7lsal6oY+6q3PjfA1Prxfm579TiumFRuqsUOO1OPuuJJnZ5ib/8l7mT6sJ8zdhxhNh/rTqPn/d55sO86dX9z9D3eebDvOn1YT5mzDjiTB/WkXn5+W7AAAAAIBkWEoBAAAAAMnUaSldl3qAgpg/rSbM34QZT4T506r7/HWfbzrMn17d/wx1n286zJ9WE+ZvwownwvxpFZq/Nj9TCgAAAADoPXX6TikAAAAAoMewlAIAAAAAkkm+lJrZVWa23cx2mNlNqefJw8x2mtmvzGyLmW3Ojs03s41m9kz2dl7qOVuZ2V1mttfMtrYcm3JmM7s5+5xsN7Mr00z9pinmv8XMns8+D1vM7OqW22ozP41Xj77TovHq0Xg69N0dNJ4OjVev6X1LXWjc3ZNdJPVLelbSeZJmS/qlpItSzpRz7p2SFhxz7GuSbsrev0nSV1PPecx8l0l6t6St080s6aLsczFH0pLsc9Rfw/lvkfTnbe5bm/lpPGkf9N2d2Wk8XSM0Xv3c9J22ERqvfm4aT9dHY/o+wZ+htMZTf6d0paQd7v6cu78h6R5JqxLP1KlVku7O3r9b0jXpRjmeu2+StO+Yw1PNvErSPe5+yN1/LWmHJj9XyUwx/1TqND+NdwF9J52fxruAxvkaXoLa9i3RuGi8DLVtvOl9S9U3nnopPUvSrpbrw9mxunNJPzazx8xsbXbsTHcfkaTs7RnJpstvqpmb9Hm53swez15ScORlD3Wav06zzESExum7O+o2T140Xg91b7xOs8xEhL4lGu+GOs0yExEaj9C3VFLjqZdSa3OsCb+j5lJ3f7ekD0u6zswuSz1QyZryefm2pPMlLZc0IumO7Hid5q/TLDMRufGmfE6a0LdUv3nyovH0mtB4nWaZich9S835vNB4dSI33qTPSWmNp15KhyUtarl+tqTdiWbJzd13Z2/3StqgyW9H7zGzhZKUvd2bbsLcppq5EZ8Xd9/j7uPuPiHpu3rzZQF1mr9Os+QWpHH67o66zZMLjafXkMbrNEtuQfqWaLwb6jRLbkEab3TfUrmNp15KH5W01MyWmNlsSasl3Z94phMys0EzO/XI+5I+JGmrJudek91tjaQfpZlwRqaa+X5Jq81sjpktkbRU0s8TzHdCR/4iZz6qyc+DVK/5aTwd+u4OGk+HxqtH32nRePVoPJ1G9y2V3Hg3ztZ0ooukqyU9rcmzMn0+9Tw55j1Pk2eT+qWkbUdmlvQ2SQ9LeiZ7Oz/1rMfMvV6T31Y/rMl/vfjkiWaW9Pnsc7Jd0odrOv9fSfqVpMez+BfWcX4aT9YHfXdvfhpP0wiNd2d2+k7XCI13Z3YaT9NHY/o+wZ+htMYtexAAAAAAAF2X+uW7AAAAAIAexlIKAAAAAEiGpRQAAAAAkAxLKQAAAAAgGZZSAAAAAEAyLKUAAAAAgGRYSgEAAAAAyfxvwYhyBI6M4lAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x648 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(ENV_NAME)\n",
    "env.reset()\n",
    "\n",
    "n_cols = 5\n",
    "n_rows = 2\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        ax = fig.add_subplot(n_rows, n_cols, row * n_cols + col + 1)\n",
    "        ax.imshow(env.render('rgb_array'))\n",
    "        env.step(env.action_space.sample())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing game image \n",
    "\n",
    "Raw Atari images are large, 210x160x3 by default. However, we don't need that level of detail in order to learn them.\n",
    "\n",
    "We can thus save a lot of time by preprocessing game image, including\n",
    "* Resizing to a smaller shape, 64 x 64\n",
    "* Converting to grayscale\n",
    "* Cropping irrelevant image parts (top & bottom)\n",
    "\n",
    "Tip: You can implement your own grayscale converter and assign a huge weight to the red channel. This dirty trick is not necessary but it will speed up learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.core import ObservationWrapper\n",
    "from gym.spaces import Box\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class PreprocessAtariObs(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"A gym wrapper that crops, scales image into the desired shapes and optionally grayscales it.\"\"\"\n",
    "        super().__init__(env)\n",
    "\n",
    "        self.img_size = (64, 64, 1)\n",
    "        self.observation_space = Box(0.0, 1.0, self.img_size)\n",
    "\n",
    "    def _to_gray_scale(self, rgb, channel_weights=[0.8, 0.1, 0.1]):\n",
    "        #<YOUR CODE>\n",
    "        return cv2.cvtColor(rgb, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    def observation(self, img):\n",
    "        \"\"\"what happens to each observation\"\"\"\n",
    "\n",
    "        # Here's what you need to do:\n",
    "        #  * Crop image, remove irrelevant parts.\n",
    "        #  * Resize image to self.img_size. Use cv2.resize or any other library you want,\n",
    "        #    e.g. PIL or Keras. Do not use skimage.transform.resize because it is roughly\n",
    "        #    6x slower than cv2.resize.\n",
    "        #  * Cast image to grayscale.\n",
    "        #  * Convert image pixels to (0, 1) range, float32 type.\n",
    "\n",
    "        #<YOUR CODE>\n",
    "        processed_img=img[30:-15,5:-6]\n",
    "        processed_img=cv2.resize(processed_img,self.img_size[:-1])\n",
    "        processed_img=self._to_gray_scale(processed_img)\n",
    "        processed_img=MinMaxScaler().fit_transform(processed_img)\n",
    "        processed_img=processed_img.reshape(self.img_size).astype(np.float32)\n",
    "        return processed_img#<YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formal tests seem fine. Here's an example of what you'll get.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "# spawn game instance for tests\n",
    "env = gym.make(ENV_NAME)  # create raw env\n",
    "env = PreprocessAtariObs(env)\n",
    "\n",
    "observation_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "\n",
    "# test observation\n",
    "assert obs.ndim == 3, \"observation must be [height, width, channels] even if there's just one channel\"\n",
    "assert obs.shape == observation_shape, (obs.shape, observation_shape)\n",
    "assert obs.dtype == np.float32\n",
    "assert len(np.unique(obs)) > 2, \"your image must not be binary\"\n",
    "assert 0 <= np.min(obs) and np.max(obs) <= 1, \"convert image pixels to (0,1) range\"\n",
    "assert np.max(obs) >= 0.5, \"It would be easier to see a brighter observation\"\n",
    "assert np.mean(obs) >= 0.1, \"It would be easier to see a brighter observation\"\n",
    "\n",
    "assert np.max(obs) >= 0.5, \"It would be easier to see a brighter observation\"\n",
    "assert np.mean(obs) >= 0.1, \"It would be easier to see a brighter observation\"\n",
    "\n",
    "print(\"Formal tests seem fine. Here's an example of what you'll get.\")\n",
    "\n",
    "\n",
    "n_cols = 5\n",
    "n_rows = 2\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "obs = env.reset()\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        ax = fig.add_subplot(n_rows, n_cols, row * n_cols + col + 1)\n",
    "        ax.imshow(obs[:, :, 0], interpolation='none', cmap='gray')\n",
    "        obs, _, _, _ = env.step(env.action_space.sample())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About the game:** You have 5 lives and get points for breaking the wall. Higher bricks cost more than the lower ones. There are 4 actions: start game (should be called at the beginning and after each life is lost), move left, move right and do nothing. There are some common wrappers used for Atari environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import atari_wrappers\n",
    "\n",
    "def PrimaryAtariWrap(env, clip_rewards=True):\n",
    "    assert 'NoFrameskip' in env.spec.id\n",
    "\n",
    "    # This wrapper holds the same action for <skip> frames and outputs\n",
    "    # the maximal pixel value of 2 last frames (to handle blinking\n",
    "    # in some envs)\n",
    "    env = atari_wrappers.MaxAndSkipEnv(env, skip=4)\n",
    "\n",
    "    # This wrapper sends done=True when each life is lost\n",
    "    # (not all the 5 lives that are givern by the game rules).\n",
    "    # It should make easier for the agent to understand that losing is bad.\n",
    "    env = atari_wrappers.EpisodicLifeEnv(env)\n",
    "\n",
    "    # This wrapper laucnhes the ball when an episode starts.\n",
    "    # Without it the agent has to learn this action, too.\n",
    "    # Actually it can but learning would take longer.\n",
    "    env = atari_wrappers.FireResetEnv(env)\n",
    "\n",
    "    # This wrapper transforms rewards to {-1, 0, 1} according to their sign\n",
    "    if clip_rewards:\n",
    "        env = atari_wrappers.ClipRewardEnv(env)\n",
    "\n",
    "    # This wrapper is yours :)\n",
    "    env = PreprocessAtariObs(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame buffer\n",
    "\n",
    "Our agent can only process one observation at a time, so we gotta make sure it contains enough information to fing optimal actions. For instance, agent has to react to moving objects so he must be able to measure object's velocity.\n",
    "\n",
    "To do so, we introduce a buffer that stores 4 last images. This time everything is pre-implemented for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from framebuffer import FrameBuffer\n",
    "\n",
    "\n",
    "def make_env(clip_rewards=True, seed=None):\n",
    "    env = gym.make(ENV_NAME)  # create raw env\n",
    "    if seed is not None:\n",
    "        env.seed(seed)\n",
    "    env = PrimaryAtariWrap(env, clip_rewards)\n",
    "    env = FrameBuffer(env, n_frames=4, dim_order='tensorflow')\n",
    "    return env\n",
    "\n",
    "\n",
    "env = make_env()\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_shape = env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    obs, _, _, _ = env.step(env.action_space.sample())\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Game image\")\n",
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[12,10])\n",
    "plt.title(\"Agent observation (4 frames left to right)\")\n",
    "plt.imshow(obs.transpose([0, 2, 1]).reshape([state_shape[0], -1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN as it is (4 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a network\n",
    "\n",
    "We now need to build a neural network that can map images to state q-values. This network will be called on every agent's step so it better not be resnet-152 unless you have an array of GPUs. Instead, you can use strided convolutions with a small number of features to save time and memory.\n",
    "\n",
    "You can build any architecture you want, but for reference, here's something that will more or less work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/dqn_arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dueling network: (+2 pts)**\n",
    "$$Q_{\\theta}(s, a) = V_{\\eta}(f_{\\xi}(s)) + A_{\\psi}(f_{\\xi}(s), a) - \\frac{\\sum_{a'}A_{\\psi}(f_{\\xi}(s), a')}{N_{actions}},$$\n",
    "where $\\xi$, $\\eta$, and $\\psi$ are, respectively, the parameters of the\n",
    "shared encoder $f_$ , of the value stream $V_\\eta$ , and of the advan\n",
    "tage stream $A_\\psi$; and $\\theta = \\{\\xi, \\eta, \\psi\\}$ is their concatenation.\n",
    "\n",
    "For the architecture on the image $V$ and $A$ heads can follow the dense layer instead of $Q$. Please don't worry that the model becomes a little bigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.keras import models\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, name, state_shape, n_actions, epsilon=0, reuse=False):\n",
    "        \"\"\"A simple DQN agent\"\"\"\n",
    "        with tf.variable_scope(name, reuse=reuse):\n",
    "\n",
    "            #<YOUR CODE: define your network body here. Please make sure you don't use any layers created elsewhere>\n",
    "            conv2d_1=Conv2D(16,3,strides=(2,2),activation='relu',input_shape=state_shape)\n",
    "            conv2d_2=Conv2D(32,3,strides=(2,2),activation='relu')\n",
    "            conv2d_3=Conv2D(64,3,strides=(2,2),activation='relu')\n",
    "            flatten=Flatten()\n",
    "            dense=Dense(256,activation='relu')\n",
    "            output=Dense(n_actions,activation='linear')\n",
    "            \n",
    "            # prepare a graph for agent step\n",
    "            self.state_t = tf.placeholder('float32', [None, ] + list(state_shape))\n",
    "            self.qvalues_t = self.get_symbolic_qvalues(self.state_t)\n",
    "\n",
    "        self.weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=name)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def get_symbolic_qvalues(self, state_t):\n",
    "        \"\"\"takes agent's observation, returns qvalues. Both are tf Tensors\"\"\"\n",
    "        #<YOUR CODE: apply your network layers here>\n",
    "        qvalues = output(dense(flatten(conv2d_3(conv2d_2(conv2d_1(state_t))))))#<YOUR CODE: symbolic tensor for q-values>\n",
    "\n",
    "        assert tf.is_numeric_tensor(qvalues) and qvalues.shape.ndims == 2, \\\n",
    "            \"please return 2d tf tensor of qvalues [you got %s]\" % repr(qvalues)\n",
    "        assert int(qvalues.shape[1]) == n_actions\n",
    "\n",
    "        return qvalues\n",
    "\n",
    "    def get_qvalues(self, state_t):\n",
    "        \"\"\"Same as symbolic step except it operates on numpy arrays\"\"\"\n",
    "        sess = tf.get_default_session()\n",
    "        return sess.run(self.qvalues_t, {self.state_t: state_t})\n",
    "\n",
    "    def sample_actions(self, qvalues):\n",
    "        \"\"\"pick actions given qvalues. Uses epsilon-greedy exploration strategy. \"\"\"\n",
    "        epsilon = self.epsilon\n",
    "        batch_size, n_actions = qvalues.shape\n",
    "        random_actions = np.random.choice(n_actions, size=batch_size)\n",
    "        best_actions = qvalues.argmax(axis=-1)\n",
    "        should_explore = np.random.choice([0, 1], batch_size, p=[1-epsilon, epsilon])\n",
    "        return np.where(should_explore, random_actions, best_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent(\"dqn_agent\", state_shape, n_actions, epsilon=1)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try out our agent to see if it raises any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(env, agent, n_games=1, greedy=False, t_max=10000):\n",
    "    \"\"\" Plays n_games full games. If greedy, picks actions as argmax(qvalues). Returns mean reward. \"\"\"\n",
    "    rewards = []\n",
    "    for _ in range(n_games):\n",
    "        s = env.reset()\n",
    "        reward = 0\n",
    "        for _ in range(t_max):\n",
    "            qvalues = agent.get_qvalues([s])\n",
    "            action = qvalues.argmax(axis=-1)[0] if greedy else agent.sample_actions(qvalues)[0]\n",
    "            s, r, done, _ = env.step(action)\n",
    "            reward += r\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        rewards.append(reward)\n",
    "    return np.mean(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(env, agent, n_games=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience replay\n",
    "For this assignment, we provide you with experience replay buffer. If you implemented experience replay buffer in last week's assignment, you can copy-paste it here __to get 2 bonus points__.\n",
    "\n",
    "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/exp_replay.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The interface is fairly simple:\n",
    "* `exp_replay.add(obs, act, rw, next_obs, done)` - saves (s,a,r,s',done) tuple into the buffer\n",
    "* `exp_replay.sample(batch_size)` - returns observations, actions, rewards, next_observations and is_done for `batch_size` random samples.\n",
    "* `len(exp_replay)` - returns number of elements stored in replay buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay_buffer import ReplayBuffer\n",
    "exp_replay = ReplayBuffer(10)\n",
    "\n",
    "for _ in range(30):\n",
    "    exp_replay.add(env.reset(), env.action_space.sample(), 1.0, env.reset(), done=False)\n",
    "\n",
    "obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(5)\n",
    "\n",
    "assert len(exp_replay) == 10, \"experience replay size should be 10 because that's what maximum capacity is\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def play_and_record(initial_state, agent, env, exp_replay, n_steps=1):\n",
    "    \"\"\"\n",
    "    Play the game for exactly n steps, record every (s,a,r,s', done) to replay buffer. \n",
    "    Whenever game ends, add record with done=True and reset the game.\n",
    "    It is guaranteed that env has done=False when passed to this function.\n",
    "\n",
    "    PLEASE DO NOT RESET ENV UNLESS IT IS \"DONE\"\n",
    "\n",
    "    :returns: return sum of rewards over time and the state in which the env stays\n",
    "    \"\"\"\n",
    "    # initial state\n",
    "    s = initial_state\n",
    "    sum_rewards = 0\n",
    "\n",
    "    # Play the game for n_steps as per instructions above\n",
    "    #<YOUR CODE>\n",
    "    for step in tqdm(range(n_steps)):\n",
    "        qvalues = agent.get_qvalues([s])\n",
    "        action=agent.sample_actions(qvalues)[0]\n",
    "        next_s, r, done, _ = env.step(action)\n",
    "        sum_rewards+=r\n",
    "        exp_replay.add(s, action, r, next_s, done)\n",
    "        s=next_s\n",
    "        if done:\n",
    "            env.reset()\n",
    "           \n",
    "    return sum_rewards, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1000/1000 [00:05<00:00, 187.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# testing your code.\n",
    "exp_replay = ReplayBuffer(2000)\n",
    "\n",
    "state = env.reset()\n",
    "play_and_record(state, agent, env, exp_replay, n_steps=1000)\n",
    "\n",
    "# if you're using your own experience replay buffer, some of those tests may need correction.\n",
    "# just make sure you know what your code does\n",
    "assert len(exp_replay) == 1000, \"play_and_record should have added exactly 1000 steps, \"\\\n",
    "                                 \"but instead added %i\" % len(exp_replay)\n",
    "is_dones = list(zip(*exp_replay._storage))[-1]\n",
    "\n",
    "assert 0 < np.mean(is_dones) < 0.1, \"Please make sure you restart the game whenever it is 'done' and record the is_done correctly into the buffer.\"\\\n",
    "                                    \"Got %f is_done rate over %i steps. [If you think it's your tough luck, just re-run the test]\" % (\n",
    "                                        np.mean(is_dones), len(exp_replay))\n",
    "\n",
    "for _ in range(100):\n",
    "    obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(\n",
    "        10)\n",
    "    assert obs_batch.shape == next_obs_batch.shape == (10,) + state_shape\n",
    "    assert act_batch.shape == (10,), \\\n",
    "        \"actions batch should have shape (10,) but is instead %s\" % str(act_batch.shape)\n",
    "    assert reward_batch.shape == (10,), \\\n",
    "        \"rewards batch should have shape (10,) but is instead %s\" % str(reward_batch.shape)\n",
    "    assert is_done_batch.shape == (10,), \\\n",
    "        \"is_done batch should have shape (10,) but is instead %s\" % str(is_done_batch.shape)\n",
    "    assert [int(i) in (0, 1) for i in is_dones], \"is_done should be strictly True or False\"\n",
    "    assert [0 <= a < n_actions for a in act_batch], \"actions should be within [0, n_actions)\"\n",
    "\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target networks\n",
    "\n",
    "We also employ the so called \"target network\" - a copy of neural network weights to be used for reference Q-values:\n",
    "\n",
    "The network itself is an exact copy of agent network, but it's parameters are not trained. Instead, they are moved here from agent's actual network every so often.\n",
    "\n",
    "$$ Q_{reference}(s,a) = r + \\gamma \\cdot \\max _{a'} Q_{target}(s',a') $$\n",
    "\n",
    "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/target_net.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_network = DQNAgent(\"target_network\", state_shape, n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weigths_into_target_network(agent, target_network):\n",
    "    \"\"\" assign target_network.weights variables to their respective agent.weights values. \"\"\"\n",
    "    assigns = []\n",
    "    for w_agent, w_target in zip(agent.weights, target_network.weights):\n",
    "        assigns.append(tf.assign(w_target, w_agent, validate_shape=True))\n",
    "    # tf.get_default_session().run(assigns)\n",
    "    return assigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It works!\n"
     ]
    }
   ],
   "source": [
    "# create the tf copy graph only once.\n",
    "copy_step = load_weigths_into_target_network(agent, target_network)\n",
    "sess.run(copy_step)\n",
    "# check that it works\n",
    "sess.run([tf.assert_equal(w, w_target) for w, w_target in zip(agent.weights, target_network.weights)])\n",
    "print(\"It works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning with... Q-learning\n",
    "Here we write a function similar to `agent.update` from tabular q-learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholders that will be fed with exp_replay.sample(batch_size)\n",
    "obs_ph = tf.placeholder(tf.float32, shape=(None,) + state_shape)\n",
    "actions_ph = tf.placeholder(tf.int32, shape=[None])\n",
    "rewards_ph = tf.placeholder(tf.float32, shape=[None])\n",
    "next_obs_ph = tf.placeholder(tf.float32, shape=(None,) + state_shape)\n",
    "is_done_ph = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "is_not_done = 1 - is_done_ph\n",
    "gamma = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take q-values for actions agent just took"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_qvalues = agent.get_symbolic_qvalues(obs_ph)\n",
    "current_action_qvalues = tf.reduce_sum(tf.one_hot(actions_ph, n_actions) * current_qvalues, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Q-learning TD error:\n",
    "\n",
    "$$ L = { 1 \\over N} \\sum_i [ Q_{\\theta}(s,a) - Q_{reference}(s,a) ] ^2 $$\n",
    "\n",
    "With Q-reference defined as\n",
    "\n",
    "$$ Q_{reference}(s,a) = r(s,a) + \\gamma \\cdot max_{a'} Q_{target}(s', a') $$\n",
    "\n",
    "Where\n",
    "* $Q_{target}(s',a')$ denotes q-value of next state and next action predicted by __target_network__\n",
    "* $s, a, r, s'$ are current state, action, reward and next state respectively\n",
    "* $\\gamma$ is a discount factor defined two cells above.\n",
    "\n",
    "\n",
    "__Note 1:__ there's an example input below. Feel free to experiment with it before you write the function.\n",
    "\n",
    "__Note 2:__ compute_td_loss is a source of 99% of bugs in this homework. If reward doesn't improve, it often helps to go through it line by line [with a rubber duck](https://rubberduckdebugging.com/).\n",
    "\n",
    "**Double DQN (+2 pts)**\n",
    "\n",
    "$$ Q_{reference}(s,a) = r(s, a) + \\gamma \\cdot\n",
    "Q_{target}(s',argmax_{a'}Q_\\theta(s', a')) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "next_qvalues_target = target_network.get_symbolic_qvalues(next_obs_ph)*is_not_done#<YOUR CODE: compute q-values for NEXT states with target network>\n",
    "next_state_values_target = tf.reduce_max(next_qvalues_target,axis=1)#<YOUR CODE: compute state values by taking max over next_qvalues_target for all actions>\n",
    "reference_qvalues = rewards_ph+gamma*next_qvalues_target#<YOUR CODE: compute Q_reference(s,a) as per formula above>\n",
    "\n",
    "# Define loss function for sgd.\n",
    "td_loss = (current_action_qvalues - reference_qvalues) ** 2\n",
    "td_loss = tf.reduce_mean(td_loss)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(td_loss, var_list=agent.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splendid!\n"
     ]
    }
   ],
   "source": [
    "for chk_grad in tf.gradients(reference_qvalues, agent.weights):\n",
    "    error_msg = \"Reference q-values should have no gradient w.r.t. agent weights. Make sure you used target_network qvalues! \"\n",
    "    error_msg += \"If you know what you're doing, ignore this assert.\"\n",
    "    assert chk_grad is None or np.allclose(sess.run(chk_grad), sess.run(chk_grad * 0)), error_msg\n",
    "\n",
    "assert tf.gradients(reference_qvalues, is_not_done)[0] is not None, \"make sure you used is_not_done\"\n",
    "assert tf.gradients(reference_qvalues, rewards_ph)[0] is not None, \"make sure you used rewards\"\n",
    "assert tf.gradients(reference_qvalues, next_obs_ph)[0] is not None, \"make sure you used next states\"\n",
    "assert tf.gradients(reference_qvalues, obs_ph)[0] is None, \"reference qvalues shouldn't depend on current observation!\"  # ignore if you're certain it's ok\n",
    "print(\"Splendid!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop (3 pts)\n",
    "\n",
    "**If deadline is tonight and it has not converged:** It is ok. Send the notebook today and when it converges send it again.\n",
    "If the code is exactly the same points will not be discounted.\n",
    "\n",
    "It's time to put everything together and see if it learns anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[-3.08170170e-02, -1.57625318e-01, -1.66108966e-01,\n",
       "            3.78775299e-02, -9.70212221e-02,  7.56006539e-02,\n",
       "            1.07202321e-01,  7.43611455e-02, -1.99831575e-02,\n",
       "            9.23036337e-02,  1.77824765e-01, -1.91342533e-02,\n",
       "            5.96885532e-02,  2.62977481e-02, -1.23071328e-01,\n",
       "            2.36698985e-02],\n",
       "          [ 2.08452046e-02,  1.25956833e-01,  1.59576386e-01,\n",
       "            8.84523988e-03,  6.53619617e-02,  1.27275407e-01,\n",
       "           -1.47777379e-01, -7.54486918e-02, -3.11477929e-02,\n",
       "           -8.39537010e-02,  2.59159058e-02,  3.34077030e-02,\n",
       "           -1.50430784e-01, -1.72656655e-01,  8.94627571e-02,\n",
       "            4.34233844e-02],\n",
       "          [-1.23744503e-01, -1.66648597e-01,  2.42456794e-04,\n",
       "           -9.91725996e-02, -4.86130565e-02,  1.87496245e-02,\n",
       "           -9.13801789e-03,  1.28290772e-01,  1.52782410e-01,\n",
       "           -1.37364671e-01, -5.96728399e-02, -8.92627314e-02,\n",
       "            5.07241338e-02, -6.70021772e-03,  6.06207699e-02,\n",
       "            7.73237348e-02],\n",
       "          [-6.10925779e-02,  1.34721279e-01, -1.64123908e-01,\n",
       "           -3.63116115e-02, -1.13456845e-02, -1.58562198e-01,\n",
       "           -1.55840278e-01, -1.77739009e-01, -1.37909949e-01,\n",
       "            9.63935852e-02, -1.94972903e-02,  9.82702076e-02,\n",
       "           -7.15988427e-02,  1.12523139e-03,  8.28714073e-02,\n",
       "           -1.58239290e-01]],\n",
       " \n",
       "         [[ 7.41724074e-02, -1.34135202e-01,  8.72159600e-02,\n",
       "            1.21204704e-01,  4.77883518e-02,  1.35978311e-01,\n",
       "           -1.29378304e-01,  1.96597725e-02,  9.05312002e-02,\n",
       "            1.00802898e-01,  5.99530339e-02, -9.15825367e-05,\n",
       "           -1.13423236e-01,  9.83821154e-02, -1.81290820e-01,\n",
       "            4.11825627e-02],\n",
       "          [-4.27537411e-02,  1.15773708e-01, -4.14893925e-02,\n",
       "           -1.64220840e-01,  1.05774313e-01,  5.62030524e-02,\n",
       "            3.99726182e-02, -8.13851431e-02,  9.65760052e-02,\n",
       "            1.31134480e-01,  7.11566210e-03, -1.77698135e-01,\n",
       "            6.22065812e-02,  1.26113951e-01,  8.68508816e-02,\n",
       "            8.36493373e-02],\n",
       "          [ 1.24860883e-01,  1.63159341e-01, -1.66617647e-01,\n",
       "            1.35485560e-01,  1.63654894e-01, -1.22946963e-01,\n",
       "            3.10787559e-02,  7.00204670e-02, -5.30013144e-02,\n",
       "           -7.78021291e-02, -1.72452152e-01,  6.84936643e-02,\n",
       "           -6.00708649e-02, -1.34738773e-01, -1.14530049e-01,\n",
       "           -6.10711202e-02],\n",
       "          [ 8.49736631e-02, -5.28179705e-02, -6.34468049e-02,\n",
       "           -6.70478344e-02,  1.57317430e-01, -1.00011453e-01,\n",
       "           -1.16816461e-01,  1.48284465e-01,  9.72265899e-02,\n",
       "            1.33642197e-01,  1.72883183e-01, -8.51555392e-02,\n",
       "            1.49135143e-01, -1.65735617e-01, -9.57061350e-03,\n",
       "            1.30189329e-01]],\n",
       " \n",
       "         [[ 1.01518810e-01,  1.62252516e-01,  1.08273745e-01,\n",
       "           -3.33541632e-03, -6.60497174e-02,  9.97517109e-02,\n",
       "           -1.05095208e-01,  1.91589743e-02, -3.35761160e-02,\n",
       "           -6.31666109e-02, -5.81415743e-02,  1.89377367e-03,\n",
       "           -1.34739727e-01,  8.21729302e-02,  1.52141482e-01,\n",
       "            1.38689339e-01],\n",
       "          [-3.34137529e-02, -1.67581990e-01,  1.33402258e-01,\n",
       "           -1.27246901e-01, -1.32186830e-01,  2.11468637e-02,\n",
       "           -1.28976390e-01,  1.13227367e-01,  8.64826441e-02,\n",
       "            1.65903807e-01, -1.53949291e-01,  6.15898967e-02,\n",
       "           -7.68323466e-02,  4.38429713e-02,  2.52541304e-02,\n",
       "           -1.60574064e-01],\n",
       "          [ 1.66802824e-01,  1.25259846e-01,  4.48494405e-02,\n",
       "            1.15100414e-01, -8.57011378e-02,  1.05527014e-01,\n",
       "            8.54372084e-02, -1.73864841e-01, -1.06331915e-01,\n",
       "            1.00585699e-01,  1.69882625e-01,  1.05397612e-01,\n",
       "            9.06786323e-02,  6.82204664e-02,  8.54461491e-02,\n",
       "           -2.59181261e-02],\n",
       "          [ 3.60182226e-02,  9.18405056e-02,  1.92584395e-02,\n",
       "            1.25407934e-01, -1.74957246e-01,  1.55469835e-01,\n",
       "           -8.32276419e-02, -7.73169100e-02, -1.64597064e-01,\n",
       "           -1.12527929e-01,  8.95915926e-03,  1.19799376e-02,\n",
       "           -1.54306874e-01, -1.70300469e-01,  1.60701215e-01,\n",
       "           -7.64293969e-02]]],\n",
       " \n",
       " \n",
       "        [[[-1.78588226e-01,  1.08967304e-01, -4.62009311e-02,\n",
       "            9.09233093e-02,  8.54167640e-02, -4.44785357e-02,\n",
       "            1.07885867e-01, -1.67331263e-01,  1.75935596e-01,\n",
       "           -5.80061078e-02,  1.79477334e-02, -1.49181366e-01,\n",
       "            9.12272036e-02,  5.49695194e-02, -7.72712082e-02,\n",
       "            1.71377063e-02],\n",
       "          [ 5.07018417e-02,  1.13379478e-01,  9.24278796e-03,\n",
       "            4.48473543e-02, -2.52634287e-03, -1.19576551e-01,\n",
       "           -1.47698641e-01,  6.99892640e-02,  5.46486676e-02,\n",
       "            3.86276841e-03,  1.35857165e-01,  1.09951913e-01,\n",
       "           -1.17397964e-01, -1.46827281e-01,  1.17698461e-01,\n",
       "            1.56414986e-01],\n",
       "          [ 9.67356265e-02, -9.48197842e-02, -1.44645378e-01,\n",
       "            1.19577855e-01, -4.62790728e-02,  1.23817235e-01,\n",
       "           -4.22000885e-03, -1.08407162e-01,  1.06225848e-01,\n",
       "            9.38739479e-02, -6.75221309e-02,  4.25953418e-02,\n",
       "           -1.11730397e-03,  1.49783999e-01,  1.65455818e-01,\n",
       "           -1.47699475e-01],\n",
       "          [ 7.99576342e-02, -7.65598565e-02, -1.03152290e-01,\n",
       "            1.12964749e-01, -1.93780512e-02, -1.07682645e-02,\n",
       "            1.03682429e-01, -1.26539990e-01, -5.02729118e-02,\n",
       "            6.24817312e-02, -7.21172318e-02,  6.19588792e-03,\n",
       "           -7.41495192e-02, -2.42814422e-03, -9.10132900e-02,\n",
       "            5.35789430e-02]],\n",
       " \n",
       "         [[-1.49135053e-01, -6.07258081e-02,  3.38630527e-02,\n",
       "           -1.73715934e-01, -1.85305029e-02, -1.87675655e-03,\n",
       "           -5.50051033e-03, -2.27357149e-02,  2.93892622e-02,\n",
       "            5.61138093e-02, -3.81390899e-02,  7.10994899e-02,\n",
       "           -3.88568342e-02,  1.78703010e-01,  1.66250527e-01,\n",
       "           -3.76616567e-02],\n",
       "          [-3.41728926e-02,  5.59114516e-02,  1.45514965e-01,\n",
       "            1.64487511e-01, -1.20287552e-01, -1.50790647e-01,\n",
       "            1.70021266e-01,  7.37191737e-03, -1.29200786e-01,\n",
       "            1.25601202e-01,  7.92950392e-02,  8.44491124e-02,\n",
       "           -9.85098705e-02,  5.98986596e-02, -1.32227927e-01,\n",
       "            1.68760359e-01],\n",
       "          [ 2.66400576e-02,  1.15312397e-01,  8.78438950e-02,\n",
       "           -8.96527469e-02, -8.45204070e-02, -1.33283123e-01,\n",
       "           -1.17190242e-01, -1.06614113e-01, -1.52917385e-01,\n",
       "           -1.06692292e-01, -1.14189655e-01,  1.77656472e-01,\n",
       "            1.22358888e-01, -1.26369610e-01,  1.06790751e-01,\n",
       "           -1.76777989e-01],\n",
       "          [-7.50861764e-02,  9.41190422e-02,  3.83379757e-02,\n",
       "           -8.14834312e-02,  1.66077346e-01,  1.74451619e-01,\n",
       "            5.02553135e-02,  6.50558174e-02, -4.33440357e-02,\n",
       "            3.67072821e-02,  2.79066265e-02, -1.43508017e-02,\n",
       "           -8.85680914e-02,  7.05856681e-02,  1.49548382e-01,\n",
       "            2.73523182e-02]],\n",
       " \n",
       "         [[ 5.00965714e-02, -1.70247570e-01,  2.05796361e-02,\n",
       "            1.05153859e-01,  6.45215809e-02,  6.34903312e-02,\n",
       "           -1.23074770e-01, -8.53453577e-03, -1.55942142e-01,\n",
       "           -6.46124259e-02, -1.31141394e-01, -1.67352155e-01,\n",
       "            9.98550057e-02,  1.68262094e-01, -1.62709028e-01,\n",
       "           -1.03583537e-01],\n",
       "          [ 3.74391824e-02,  1.25706226e-01,  8.46516490e-02,\n",
       "           -4.54774797e-02, -1.66476741e-01, -1.18539907e-01,\n",
       "           -1.00999035e-01,  1.22558206e-01,  8.38086307e-02,\n",
       "            9.32622254e-02, -1.54503286e-01,  5.44771254e-02,\n",
       "            4.42046076e-02, -5.05701602e-02, -1.54725328e-01,\n",
       "            8.54056478e-02],\n",
       "          [-1.48209333e-01,  1.31248057e-01,  3.62696052e-02,\n",
       "            1.44696325e-01, -4.17847931e-03, -1.65832937e-01,\n",
       "            3.31277549e-02,  1.46219879e-02,  1.36328369e-01,\n",
       "            8.66897702e-02, -3.41838151e-02, -4.15656120e-02,\n",
       "            5.10557741e-02,  1.10205948e-01,  9.85700190e-02,\n",
       "            2.69754529e-02],\n",
       "          [ 9.67652202e-02, -6.62363693e-02, -1.48603007e-01,\n",
       "           -1.22252628e-01,  7.84043074e-02, -9.68265533e-03,\n",
       "           -1.71019614e-01, -1.75352931e-01,  1.80297017e-01,\n",
       "            1.99568272e-03, -1.34507418e-02, -9.17649567e-02,\n",
       "            8.67651105e-02, -1.19785517e-02, -1.61082178e-01,\n",
       "            2.04489231e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 3.80743146e-02,  1.42887026e-01, -9.37914029e-02,\n",
       "           -1.30270422e-01, -1.57041639e-01, -2.26596296e-02,\n",
       "            1.54747695e-01, -9.04197767e-02,  9.09272432e-02,\n",
       "           -5.08536696e-02,  1.53878778e-02, -1.63776934e-01,\n",
       "            1.42722934e-01,  3.72617245e-02,  2.65471190e-02,\n",
       "           -2.77157426e-02],\n",
       "          [-1.57305300e-01, -1.82509154e-01, -1.59751058e-01,\n",
       "            1.40764296e-01,  4.89083529e-02,  1.70474887e-01,\n",
       "           -1.02929987e-01, -2.90186107e-02, -7.21347332e-02,\n",
       "           -8.89985040e-02, -1.60248518e-01, -1.71974897e-01,\n",
       "            1.73489809e-01,  9.56200957e-02, -1.58803165e-02,\n",
       "            9.10895169e-02],\n",
       "          [-2.15059519e-03,  1.36392057e-01, -7.90466368e-03,\n",
       "           -1.52897269e-01,  3.10687423e-02,  3.24151069e-02,\n",
       "           -8.34099427e-02,  7.20967352e-02,  1.77554667e-01,\n",
       "           -1.02371469e-01,  7.56929815e-02, -2.62239128e-02,\n",
       "           -1.74896047e-01,  1.34271532e-02, -1.78469002e-01,\n",
       "           -1.48634389e-01],\n",
       "          [ 1.24393255e-01, -8.22516754e-02,  1.17240578e-01,\n",
       "           -1.36531353e-01, -1.53651938e-01, -1.70617878e-01,\n",
       "           -1.36198387e-01, -1.66755110e-01,  1.23639345e-01,\n",
       "           -3.88007760e-02,  4.22495902e-02,  9.25984979e-02,\n",
       "           -5.00588119e-03, -1.62116647e-01,  2.44207233e-02,\n",
       "           -1.10560462e-01]],\n",
       " \n",
       "         [[ 1.24210626e-01, -7.98989236e-02,  1.39015883e-01,\n",
       "            1.27424002e-02,  9.15977955e-02, -1.43084437e-01,\n",
       "           -5.26980907e-02, -1.47319421e-01, -9.36045349e-02,\n",
       "            1.02698684e-01,  1.51893526e-01,  1.68300420e-01,\n",
       "           -1.49793297e-01,  1.77668035e-03,  2.67499685e-02,\n",
       "           -1.23503529e-01],\n",
       "          [ 4.00445312e-02,  8.41160119e-03,  3.04794908e-02,\n",
       "           -1.77438453e-01,  5.97518831e-02, -1.75182030e-01,\n",
       "            1.33502841e-01, -1.60627693e-01,  3.57576162e-02,\n",
       "           -1.55591428e-01,  1.30937546e-01, -1.53456241e-01,\n",
       "           -1.74686238e-01, -1.71679556e-01,  1.08794361e-01,\n",
       "            1.13524407e-01],\n",
       "          [-3.05597633e-02, -1.12000704e-02, -4.96013463e-03,\n",
       "           -1.85274929e-02, -6.74422979e-02, -1.05645940e-01,\n",
       "           -6.96521848e-02,  1.68249518e-01,  7.93521106e-02,\n",
       "            4.79430556e-02, -5.38507402e-02,  6.27841651e-02,\n",
       "            1.73335403e-01,  1.10372066e-01,  4.03483212e-02,\n",
       "            2.14049816e-02],\n",
       "          [ 8.35548937e-02, -7.88942724e-02, -1.34985924e-01,\n",
       "            1.46426886e-01, -1.43519282e-01,  9.37312841e-02,\n",
       "           -4.98293489e-02, -9.85243246e-02, -1.16362102e-01,\n",
       "           -2.40349323e-02,  1.66464031e-01,  3.93873751e-02,\n",
       "           -8.34531188e-02, -1.70922577e-02,  3.92210484e-02,\n",
       "            1.36982948e-01]],\n",
       " \n",
       "         [[ 3.26457620e-02, -2.24460661e-02, -1.51192203e-01,\n",
       "           -1.53843343e-01, -3.39348763e-02, -6.89646378e-02,\n",
       "           -5.04410565e-02,  2.96823531e-02,  1.80543929e-01,\n",
       "            1.62213236e-01, -1.62352666e-01, -1.80967137e-01,\n",
       "           -1.13890827e-01,  1.11305952e-01, -7.70552456e-03,\n",
       "            1.53544724e-01],\n",
       "          [ 1.24317706e-01, -9.59248990e-02, -2.86339968e-02,\n",
       "           -1.26405045e-01,  1.39258623e-01, -1.16747856e-01,\n",
       "            1.17800057e-01,  4.43651825e-02,  1.26871377e-01,\n",
       "           -7.30444044e-02, -8.75611305e-02,  8.35232139e-02,\n",
       "           -1.18773527e-01, -1.07250117e-01,  2.62656212e-02,\n",
       "            1.55910492e-01],\n",
       "          [ 4.86744791e-02,  4.78777140e-02, -1.04006201e-01,\n",
       "           -1.00757062e-01, -1.52957082e-01, -1.75627545e-01,\n",
       "            1.00693733e-01, -4.05871719e-02,  1.48845553e-01,\n",
       "           -1.37649864e-01,  5.47667146e-02, -3.57913971e-02,\n",
       "            1.04936808e-02,  5.94500154e-02,  8.84567499e-02,\n",
       "            1.73549086e-01],\n",
       "          [ 1.77933037e-01,  3.52350026e-02, -1.51044279e-01,\n",
       "            3.28396261e-03,  1.44613445e-01, -1.51025087e-01,\n",
       "           -1.24745801e-01,  1.16160303e-01,  9.93633866e-02,\n",
       "           -9.71851498e-02,  7.77833164e-02, -1.05697483e-01,\n",
       "           -1.70912743e-01,  3.19544375e-02, -3.80885154e-02,\n",
       "            1.12806380e-01]]]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[[[ 1.73468068e-02,  7.86944851e-02,  5.94917312e-02, ...,\n",
       "            6.84541836e-02, -2.65656933e-02,  4.03426588e-03],\n",
       "          [ 4.36098874e-03,  6.81224242e-02, -8.69023055e-03, ...,\n",
       "            1.63538530e-02, -1.19992048e-02,  1.57356039e-02],\n",
       "          [-3.76113728e-02, -1.12285748e-01,  7.11960569e-02, ...,\n",
       "           -6.07400164e-02,  1.09426729e-01, -7.79153630e-02],\n",
       "          ...,\n",
       "          [ 8.32057968e-02, -3.79218832e-02,  4.95703742e-02, ...,\n",
       "           -7.67520815e-02, -1.95315257e-02, -8.36044550e-03],\n",
       "          [-1.35226771e-02,  4.28749248e-02,  1.00590192e-01, ...,\n",
       "            1.66707411e-02, -1.61802024e-03, -4.40824553e-02],\n",
       "          [ 1.00303628e-01, -6.67661726e-02,  6.78038821e-02, ...,\n",
       "            5.18093780e-02, -9.94113237e-02,  3.23765948e-02]],\n",
       " \n",
       "         [[ 3.52226868e-02,  3.75122651e-02, -8.66141915e-02, ...,\n",
       "           -3.83775681e-02,  7.27942064e-02, -8.63054246e-02],\n",
       "          [ 1.03083096e-01,  4.42259833e-02, -3.73183936e-02, ...,\n",
       "            6.14256635e-02,  8.70397314e-02, -4.93475050e-03],\n",
       "          [-3.97298709e-02,  1.78120658e-02,  2.23245099e-02, ...,\n",
       "           -5.91729954e-02,  3.84899229e-03, -1.10845171e-01],\n",
       "          ...,\n",
       "          [ 1.07866324e-01, -7.55916685e-02, -9.24246088e-02, ...,\n",
       "            2.95212790e-02, -1.11641437e-01,  9.26067457e-02],\n",
       "          [ 3.57352123e-02,  5.99075928e-02, -7.45941624e-02, ...,\n",
       "            5.18602356e-02, -9.29055884e-02, -9.28301215e-02],\n",
       "          [-1.14374913e-01,  7.01815262e-02, -4.12376300e-02, ...,\n",
       "            1.72592476e-02,  1.05677836e-01, -2.86272913e-02]],\n",
       " \n",
       "         [[ 5.17904684e-02,  7.19942674e-02, -6.55717552e-02, ...,\n",
       "           -7.38379359e-02,  1.01026647e-01,  8.25158283e-02],\n",
       "          [ 5.34296706e-02,  3.41972485e-02,  4.41898406e-03, ...,\n",
       "           -1.06367461e-01,  6.95186928e-02, -9.69097391e-02],\n",
       "          [-2.01730281e-02,  1.00957133e-01,  1.15198381e-01, ...,\n",
       "            2.78088823e-02, -8.11482221e-02, -5.91170527e-02],\n",
       "          ...,\n",
       "          [-8.05364996e-02, -1.18922144e-02, -1.14353955e-01, ...,\n",
       "            1.85302272e-02, -1.22488588e-02, -7.46819973e-02],\n",
       "          [-9.41868871e-02, -5.01446351e-02,  6.99047968e-02, ...,\n",
       "           -8.00040737e-02,  2.97590718e-02, -1.06828630e-01],\n",
       "          [-1.04688257e-02,  4.64081541e-02, -8.47977400e-02, ...,\n",
       "           -1.01368561e-01, -3.92232910e-02, -6.77571297e-02]]],\n",
       " \n",
       " \n",
       "        [[[-5.78059219e-02, -1.08816698e-01,  8.97428021e-02, ...,\n",
       "            5.35592660e-02, -1.13966852e-01,  3.79487351e-02],\n",
       "          [-3.79481241e-02,  8.48491862e-02, -6.97348863e-02, ...,\n",
       "           -3.22346389e-02,  5.02514094e-03, -2.00091302e-02],\n",
       "          [ 5.75818047e-02,  4.83669117e-02,  3.95694599e-02, ...,\n",
       "           -4.92104888e-02, -8.81696939e-02,  9.64055732e-02],\n",
       "          ...,\n",
       "          [-1.13264404e-01,  1.10446043e-01, -4.74121124e-02, ...,\n",
       "            9.19848010e-02,  8.16968307e-02,  3.02854404e-02],\n",
       "          [ 3.56759131e-03, -1.09617434e-01, -9.66795087e-02, ...,\n",
       "           -3.29174772e-02,  1.15886889e-01,  5.78121319e-02],\n",
       "          [-5.70769608e-03,  4.92674112e-03, -6.88751712e-02, ...,\n",
       "            8.00888985e-03,  1.00984998e-01,  4.01164591e-03]],\n",
       " \n",
       "         [[-1.04334638e-01, -1.12173922e-01,  1.04579903e-01, ...,\n",
       "           -2.07192749e-02,  7.94306397e-05, -9.09289569e-02],\n",
       "          [-8.55619013e-02, -1.15475819e-01,  1.03808619e-01, ...,\n",
       "           -9.59160253e-02,  8.97742733e-02, -1.46556944e-02],\n",
       "          [-1.38325691e-02, -6.57360703e-02,  1.53901204e-02, ...,\n",
       "            3.82602587e-02,  6.46224990e-02,  8.87253135e-03],\n",
       "          ...,\n",
       "          [ 5.26607111e-02, -4.82138619e-02,  1.70093104e-02, ...,\n",
       "            9.42052826e-02, -1.16677366e-01, -1.91924125e-02],\n",
       "          [ 1.09508641e-01, -1.13027394e-01, -1.03523418e-01, ...,\n",
       "            6.62236661e-03, -1.84955299e-02,  1.17213614e-01],\n",
       "          [-9.86923799e-02,  1.09557532e-01,  2.06445977e-02, ...,\n",
       "            3.66654471e-02,  4.97013554e-02, -7.56391212e-02]],\n",
       " \n",
       "         [[-8.46125931e-03, -1.04907915e-01, -9.08110291e-02, ...,\n",
       "           -3.55028510e-02, -2.98453346e-02,  5.47023043e-02],\n",
       "          [ 9.23075527e-03,  1.11086614e-01,  6.82570413e-02, ...,\n",
       "           -1.01582028e-01,  2.14432701e-02,  5.36050871e-02],\n",
       "          [-1.97906122e-02,  5.83609119e-02,  1.09374277e-01, ...,\n",
       "           -6.25024885e-02, -4.33751792e-02, -5.16780764e-02],\n",
       "          ...,\n",
       "          [-1.04805417e-01,  8.77027884e-02, -1.89442784e-02, ...,\n",
       "            1.13041021e-01,  1.28752664e-02,  4.37502787e-02],\n",
       "          [ 1.02976210e-01, -6.50654882e-02, -4.29587662e-02, ...,\n",
       "            1.04759358e-01,  9.66201648e-02, -7.85834193e-02],\n",
       "          [-1.57117024e-02, -3.13644186e-02, -1.15137860e-01, ...,\n",
       "           -1.17295213e-01, -6.47331476e-02,  8.30139443e-02]]],\n",
       " \n",
       " \n",
       "        [[[-6.37376383e-02, -1.68215409e-02,  6.91264793e-02, ...,\n",
       "            7.95667619e-03, -6.85028136e-02, -1.15750052e-01],\n",
       "          [ 2.23608389e-02,  1.02347657e-02,  1.05997846e-02, ...,\n",
       "           -2.18675584e-02, -5.51128238e-02, -7.18400329e-02],\n",
       "          [-1.17063269e-01, -7.00084120e-02,  1.08519122e-02, ...,\n",
       "            1.02631904e-01, -9.34176147e-03,  1.75971538e-03],\n",
       "          ...,\n",
       "          [ 7.92429522e-02, -8.67011398e-03,  2.79298201e-02, ...,\n",
       "           -8.09916034e-02, -3.98572609e-02,  6.39788583e-02],\n",
       "          [-4.70932871e-02, -3.52979824e-02, -1.04851641e-01, ...,\n",
       "            7.10436031e-02,  9.15156975e-02,  8.56941193e-03],\n",
       "          [ 7.31130317e-02,  8.62806961e-02, -7.84892887e-02, ...,\n",
       "            1.86559334e-02, -4.58139628e-02, -1.89393908e-02]],\n",
       " \n",
       "         [[-1.11737199e-01,  1.52547434e-02, -1.92062035e-02, ...,\n",
       "           -1.25385448e-02, -7.77590275e-02,  9.83969048e-02],\n",
       "          [-1.10314429e-01,  4.93835732e-02, -4.50101942e-02, ...,\n",
       "            5.25786653e-02,  1.06816687e-01,  5.72246090e-02],\n",
       "          [-1.13517985e-01,  1.09191664e-01,  5.80874309e-02, ...,\n",
       "            2.20107362e-02, -7.89672062e-02,  1.13802873e-01],\n",
       "          ...,\n",
       "          [ 8.42520818e-02,  9.53117833e-02,  6.56385496e-02, ...,\n",
       "           -7.48120248e-03,  5.15102521e-02, -6.25508949e-02],\n",
       "          [-5.78690544e-02,  1.11940600e-01,  6.24823347e-02, ...,\n",
       "            5.34899458e-02,  1.93642601e-02, -1.03408083e-01],\n",
       "          [-9.85859782e-02, -6.78063035e-02,  2.06578597e-02, ...,\n",
       "           -6.83242828e-03, -1.16637863e-01, -4.72055376e-02]],\n",
       " \n",
       "         [[ 4.37607616e-03, -1.15160421e-01, -4.72096652e-02, ...,\n",
       "           -2.07695439e-02, -8.64949077e-03, -5.60887456e-02],\n",
       "          [ 1.81879625e-02,  1.14336275e-01, -1.14525378e-01, ...,\n",
       "           -1.04969002e-01,  7.32062086e-02, -8.86563435e-02],\n",
       "          [ 3.17633525e-02, -1.13948442e-01, -1.06059283e-01, ...,\n",
       "           -5.62668294e-02, -5.69879636e-02, -6.05808683e-02],\n",
       "          ...,\n",
       "          [ 2.42290422e-02, -2.14777812e-02, -6.07533008e-03, ...,\n",
       "            1.06114559e-01,  9.85883102e-02, -1.07983597e-01],\n",
       "          [ 1.82576999e-02,  2.72982940e-02,  4.35438752e-03, ...,\n",
       "           -1.06047794e-01,  8.14280659e-03,  6.65570721e-02],\n",
       "          [ 1.10434212e-01, -3.79417464e-02,  9.08634588e-02, ...,\n",
       "           -1.82347521e-02,  5.51805422e-02,  8.82061645e-02]]]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[[[-0.07288492, -0.07221048, -0.00172981, ..., -0.00746083,\n",
       "           -0.06375484, -0.01843341],\n",
       "          [ 0.07646754, -0.01884156,  0.0400492 , ...,  0.00388519,\n",
       "           -0.0391346 , -0.02756105],\n",
       "          [ 0.01389471,  0.05942658, -0.07534017, ...,  0.05586819,\n",
       "            0.05479535,  0.06489726],\n",
       "          ...,\n",
       "          [ 0.06796957, -0.04126873,  0.03616321, ..., -0.02552289,\n",
       "            0.05386699,  0.05150213],\n",
       "          [ 0.05158565, -0.00016689,  0.08035716, ..., -0.01380227,\n",
       "            0.02694786, -0.01360488],\n",
       "          [-0.02010898,  0.08002236, -0.05377658, ..., -0.04791143,\n",
       "           -0.05893606, -0.04256145]],\n",
       " \n",
       "         [[-0.05069932, -0.03616643, -0.02686352, ...,  0.03295996,\n",
       "           -0.01416677, -0.0160073 ],\n",
       "          [-0.01740827,  0.00193715,  0.08323831, ..., -0.06820995,\n",
       "           -0.03942492, -0.06604312],\n",
       "          [-0.00860015,  0.07031593, -0.05999688, ...,  0.04811124,\n",
       "            0.03592476,  0.05868904],\n",
       "          ...,\n",
       "          [ 0.05824693,  0.0326252 , -0.02163512, ..., -0.07271709,\n",
       "            0.01361451, -0.01232889],\n",
       "          [ 0.00157374, -0.02326715,  0.00957727, ..., -0.04745517,\n",
       "            0.08034755, -0.00867667],\n",
       "          [-0.02596651, -0.04291668,  0.0421202 , ..., -0.02027873,\n",
       "           -0.05457594,  0.04339544]],\n",
       " \n",
       "         [[ 0.00870176,  0.01286457,  0.063368  , ..., -0.0178838 ,\n",
       "           -0.01647624, -0.01779018],\n",
       "          [-0.04414859, -0.04990878,  0.00960144, ...,  0.03757238,\n",
       "           -0.04242279, -0.04472655],\n",
       "          [ 0.05674269,  0.08032992, -0.07753742, ...,  0.04489186,\n",
       "           -0.05065404,  0.07295986],\n",
       "          ...,\n",
       "          [ 0.01586616, -0.00976336, -0.06357521, ...,  0.07526214,\n",
       "            0.07488396,  0.06803528],\n",
       "          [-0.0133096 ,  0.01491942,  0.06623491, ...,  0.02638817,\n",
       "            0.04294092, -0.05995852],\n",
       "          [-0.04831579, -0.01637951,  0.00670981, ...,  0.05005682,\n",
       "           -0.04654807, -0.0030573 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00435176, -0.07137098, -0.02082095, ...,  0.05486157,\n",
       "            0.0035058 ,  0.0486258 ],\n",
       "          [-0.01445663,  0.03670484, -0.01910714, ..., -0.05250025,\n",
       "           -0.02355848, -0.07142185],\n",
       "          [-0.04623844, -0.06830959, -0.06515341, ...,  0.01139551,\n",
       "           -0.08090562,  0.00567096],\n",
       "          ...,\n",
       "          [ 0.07700262,  0.01515293,  0.07318427, ...,  0.07752255,\n",
       "           -0.05175016,  0.07525649],\n",
       "          [ 0.00522234,  0.04012988, -0.03685276, ...,  0.05801658,\n",
       "           -0.06206356,  0.01087681],\n",
       "          [ 0.02391565, -0.01058555,  0.06715737, ...,  0.01941112,\n",
       "            0.05320468,  0.05689593]],\n",
       " \n",
       "         [[-0.07510807,  0.04943524, -0.00389963, ...,  0.04417554,\n",
       "           -0.00328674, -0.03934749],\n",
       "          [ 0.01014662,  0.01810986, -0.07297286, ..., -0.00311454,\n",
       "           -0.05951613,  0.07235672],\n",
       "          [ 0.04861525,  0.04063743, -0.00360063, ...,  0.06739033,\n",
       "           -0.01139458, -0.03816839],\n",
       "          ...,\n",
       "          [-0.00123946, -0.05706165,  0.00869808, ..., -0.06969981,\n",
       "           -0.06566459, -0.03763481],\n",
       "          [ 0.02965107,  0.03004918, -0.04230521, ...,  0.03221037,\n",
       "           -0.04352101, -0.06272   ],\n",
       "          [ 0.03299681,  0.03298867, -0.03581425, ...,  0.00260607,\n",
       "           -0.070535  , -0.05340735]],\n",
       " \n",
       "         [[-0.05297621, -0.05485139, -0.07881568, ...,  0.07558955,\n",
       "            0.00840908, -0.01078586],\n",
       "          [-0.01225541,  0.00240982, -0.04753458, ...,  0.00814325,\n",
       "            0.0695615 ,  0.0513164 ],\n",
       "          [ 0.05358257, -0.07304125,  0.03524206, ...,  0.05973605,\n",
       "           -0.04067981, -0.06361761],\n",
       "          ...,\n",
       "          [ 0.02509931,  0.03133035,  0.05025245, ...,  0.0506138 ,\n",
       "            0.05595108,  0.06072178],\n",
       "          [-0.06660378, -0.03210811,  0.06611735, ...,  0.06411267,\n",
       "            0.06532774,  0.02393615],\n",
       "          [-0.08231013,  0.07596513,  0.03412601, ..., -0.03311712,\n",
       "           -0.07398194, -0.07188992]]],\n",
       " \n",
       " \n",
       "        [[[-0.03994668, -0.00125263,  0.08235902, ..., -0.07383768,\n",
       "           -0.07999661, -0.04870294],\n",
       "          [ 0.04134574, -0.02464756, -0.04015273, ..., -0.01266507,\n",
       "            0.02278557, -0.02961872],\n",
       "          [ 0.00965909, -0.00407189, -0.03374783, ..., -0.00126976,\n",
       "           -0.06719735, -0.05771828],\n",
       "          ...,\n",
       "          [ 0.00088549, -0.05369121, -0.08107688, ..., -0.06201848,\n",
       "            0.05266673, -0.04043438],\n",
       "          [ 0.01917318,  0.07353524, -0.02387466, ...,  0.07424212,\n",
       "           -0.02276608,  0.01683352],\n",
       "          [ 0.05703821,  0.00094527, -0.03509979, ...,  0.04212875,\n",
       "           -0.04631428,  0.02900404]],\n",
       " \n",
       "         [[-0.0733788 , -0.05716829,  0.0798995 , ...,  0.07774902,\n",
       "            0.01068565,  0.05242253],\n",
       "          [-0.05046296, -0.02126914,  0.06894634, ..., -0.00307783,\n",
       "           -0.01649459, -0.02074905],\n",
       "          [ 0.0329261 , -0.06745279,  0.05948738, ..., -0.01847742,\n",
       "           -0.01862583,  0.05638421],\n",
       "          ...,\n",
       "          [-0.08166429,  0.08141113,  0.05976411, ...,  0.00677446,\n",
       "            0.05050961,  0.02229729],\n",
       "          [-0.0825436 ,  0.01305658,  0.00222316, ...,  0.01208261,\n",
       "            0.06265716, -0.01322361],\n",
       "          [ 0.03903679,  0.02571597,  0.07558192, ..., -0.003874  ,\n",
       "            0.02827686,  0.05503664]],\n",
       " \n",
       "         [[ 0.00506554, -0.01729703,  0.0078421 , ...,  0.05879281,\n",
       "            0.00526068, -0.02396631],\n",
       "          [ 0.02362653,  0.0573683 ,  0.05899117, ..., -0.06091676,\n",
       "            0.0032706 ,  0.05146051],\n",
       "          [-0.05988204,  0.07618091, -0.03812677, ...,  0.03701204,\n",
       "            0.03466839,  0.00915483],\n",
       "          ...,\n",
       "          [ 0.08144108,  0.0634743 , -0.04568323, ...,  0.00938252,\n",
       "           -0.06805001, -0.04836269],\n",
       "          [-0.0088894 ,  0.03966806, -0.00890366, ..., -0.06254689,\n",
       "            0.05615477, -0.06515592],\n",
       "          [ 0.07053483,  0.00741468,  0.00594719, ...,  0.0351579 ,\n",
       "           -0.07572912,  0.07806943]]]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.01520992,  0.02142056,  0.03603086, ...,  0.04112576,\n",
       "         -0.00064168,  0.02347771],\n",
       "        [-0.03353071, -0.04177593,  0.03147755, ..., -0.03583943,\n",
       "         -0.03838398,  0.03358106],\n",
       "        [ 0.02347687, -0.0008319 , -0.03928968, ...,  0.03104661,\n",
       "         -0.01671651, -0.01609297],\n",
       "        ...,\n",
       "        [-0.01276438,  0.03323838, -0.03424679, ...,  0.03825736,\n",
       "          0.0342012 ,  0.03282189],\n",
       "        [ 0.03017973, -0.01035998,  0.02775357, ...,  0.0187301 ,\n",
       "         -0.01198697, -0.02490119],\n",
       "        [ 0.00328271, -0.02216436, -0.03771316, ...,  0.01237092,\n",
       "          0.00019679,  0.0222751 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32),\n",
       " array([[ 0.03874603, -0.06356808, -0.02424625,  0.07209693],\n",
       "        [ 0.03460576,  0.14924446, -0.0951542 , -0.02409403],\n",
       "        [-0.00715089,  0.09184162, -0.08953709, -0.14328057],\n",
       "        ...,\n",
       "        [-0.0024648 , -0.0754611 ,  0.1028803 , -0.0551397 ],\n",
       "        [ 0.07814834,  0.00777717,  0.06350556,  0.02962142],\n",
       "        [ 0.14252254, -0.07110979,  0.08044784,  0.11782762]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 505#<YOUR CODE: your favourite random seed>\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "env = make_env(seed)\n",
    "state_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n\n",
    "state = env.reset()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(copy_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4000/4000 [00:22<00:00, 181.02it/s]\n"
     ]
    }
   ],
   "source": [
    "REPLAY_BUFFER_SIZE = 10**5\n",
    "\n",
    "exp_replay = ReplayBuffer(REPLAY_BUFFER_SIZE)\n",
    "_, state = play_and_record(state, agent, env, exp_replay, n_steps=4000)\n",
    "\n",
    "\n",
    "def sample_batch(exp_replay, batch_size):\n",
    "    obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(batch_size)\n",
    "    return {\n",
    "        obs_ph: obs_batch,\n",
    "        actions_ph: act_batch,\n",
    "        rewards_ph: reward_batch,\n",
    "        next_obs_ph: next_obs_batch,\n",
    "        is_done_ph: is_done_batch,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps_per_epoch = 10\n",
    "batch_size = 64\n",
    "total_steps = 3 * 10**5\n",
    "decay_steps = 10**5\n",
    "\n",
    "init_epsilon = 1\n",
    "final_epsilon = 0.1\n",
    "\n",
    "loss_freq = 5\n",
    "refresh_target_network_freq = 500\n",
    "eval_freq = 500\n",
    "\n",
    "n_lives = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rw_history = []\n",
    "td_loss_history = []\n",
    "initial_state_v_history = []\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300000 [00:00<?, ?it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "100%|| 10/10 [00:00<00:00, 48.41it/s][A\n",
      "  0%|          | 0/300000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [64,4] vs. [64]\n\t [[node mul_1 (defined at <ipython-input-25-479677d8e3a3>:1) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node mul_1:\n sub (defined at <ipython-input-23-1a14313b3289>:8)\t\n model_1/dense_3/BiasAdd (defined at <ipython-input-13-8089300d1006>:32)\n\nOriginal stack trace for 'mul_1':\n  File \"/home/ubuntu/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n    yield self.process_one()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 714, in __init__\n    self.run()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2923, in _run_cell\n    return runner(coro)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3147, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-25-479677d8e3a3>\", line 1, in <module>\n    next_qvalues_target = target_network.get_symbolic_qvalues(next_obs_ph)*is_not_done#<YOUR CODE: compute q-values for NEXT states with target network>\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\", line 884, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1180, in _mul_dispatch\n    return gen_math_ops.mul(x, y, name=name)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 6490, in mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [64,4] vs. [64]\n\t [[{{node mul_1}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-77fcc9501951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_replay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mloss_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [64,4] vs. [64]\n\t [[node mul_1 (defined at <ipython-input-25-479677d8e3a3>:1) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node mul_1:\n sub (defined at <ipython-input-23-1a14313b3289>:8)\t\n model_1/dense_3/BiasAdd (defined at <ipython-input-13-8089300d1006>:32)\n\nOriginal stack trace for 'mul_1':\n  File \"/home/ubuntu/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n    yield self.process_one()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 714, in __init__\n    self.run()\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2923, in _run_cell\n    return runner(coro)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3147, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-25-479677d8e3a3>\", line 1, in <module>\n    next_qvalues_target = target_network.get_symbolic_qvalues(next_obs_ph)*is_not_done#<YOUR CODE: compute q-values for NEXT states with target network>\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\", line 884, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1180, in _mul_dispatch\n    return gen_math_ops.mul(x, y, name=name)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 6490, in mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "\n",
    "with trange(step, total_steps) as progress_bar:\n",
    "    for step in progress_bar:\n",
    "        agent.epsilon = utils.linear_decay(init_epsilon, final_epsilon, step, decay_steps)\n",
    "        \n",
    "        # play\n",
    "        _, state = play_and_record(state, agent, env, exp_replay, timesteps_per_epoch)\n",
    "\n",
    "        # train\n",
    "        _, loss_t = sess.run([train_step, td_loss], sample_batch(exp_replay, batch_size=batch_size))\n",
    "        \n",
    "        if step % loss_freq == 0:\n",
    "            td_loss_history.append(loss_t)\n",
    "            \n",
    "        if step % refresh_target_network_freq == 0:\n",
    "            # Load agent weights into target_network\n",
    "            sess.run(copy_step)\n",
    "\n",
    "        if step % eval_freq == 0:\n",
    "            # eval the agent\n",
    "            mean_rw_history.append(evaluate(\n",
    "                make_env(clip_rewards=True, seed=step), agent, n_games=3 * n_lives, greedy=True)\n",
    "            )\n",
    "            initial_state_q_values = agent.get_qvalues(\n",
    "                [make_env(seed=step).reset()]\n",
    "            )\n",
    "            initial_state_v_history.append(np.max(initial_state_q_values))\n",
    "\n",
    "            clear_output(True)\n",
    "            print(\"buffer size = %i, epsilon = %.5f\" %\n",
    "                (len(exp_replay), agent.epsilon))\n",
    "\n",
    "            plt.figure(figsize=[16, 9])\n",
    "\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.title(\"Mean reward per life\")\n",
    "            plt.plot(mean_rw_history)\n",
    "            plt.grid()\n",
    "\n",
    "            assert not np.isnan(td_loss_history[-1])\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.title(\"TD loss history (smoothened)\")\n",
    "            plt.plot(utils.smoothen(td_loss_history))\n",
    "            plt.grid()\n",
    "\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.title(\"Initial state V\")\n",
    "            plt.plot(initial_state_v_history)\n",
    "            plt.grid()\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent is evaluated for 1 life, not for a whole episode of 5 lives. Rewards in evaluation are also truncated. Cuz this is what environment the agent is learning in and in this way mean rewards per life can be compared with initial state value\n",
    "\n",
    "**The goal is to get 15 points in the real env**. So 3 or better 4 points in the preprocessed one will probably be enough. You can interrupt learning then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final scoring is done on a whole episode with all 5 lives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = evaluate(\n",
    "  make_env(clip_rewards=False, seed=9),\n",
    "    agent, n_games=30, greedy=True, t_max=10 * 1000\n",
    ") * n_lives\n",
    "print('final score:', final_score)\n",
    "assert final_score >= 15, 'not as cool as DQN can'\n",
    "print('Cool!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to interpret plots:\n",
    "\n",
    "This aint no supervised learning so don't expect anything to improve monotonously. \n",
    "* **TD loss** is the MSE between agent's current Q-values and target Q-values. It may slowly increase or decrease, it's ok. The \"not ok\" behavior includes going NaN or stayng at exactly zero before agent has perfect performance.\n",
    "* **mean reward** is the expected sum of r(s,a) agent gets over the full game session. It will oscillate, but on average it should get higher over time (after a few thousand iterations...). \n",
    " * In basic q-learning implementation it takes about 40k steps to \"warm up\" agent before it starts to get better.\n",
    "* **Initial state V** is the expected discounted reward for episode in the oppinion of the agent. It should behave more smoothly than **mean reward**. It should get higher over time but sometimes can experience drawdowns because of the agaent's overestimates.\n",
    "* **buffer size** - this one is simple. It should go up and cap at max size.\n",
    "* **epsilon** - agent's willingness to explore. If you see that agent's already at 0.01 epsilon before it's average reward is above 0 - it means you need to increase epsilon. Set it back to some 0.2 - 0.5 and decrease the pace at which it goes down.\n",
    "* Smoothing of plots is done with a gaussian kernel\n",
    "\n",
    "At first your agent will lose quickly. Then it will learn to suck less and at least hit the ball a few times before it loses. Finally it will learn to actually score points.\n",
    "\n",
    "**Training will take time.** A lot of it actually. Probably you will not see any improvment during first **150k** time steps (note that by default in this notebook agent is evaluated every 5000 time steps).\n",
    "\n",
    "But hey, long training time isn't _that_ bad:\n",
    "\n",
    "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About hyperparameters:\n",
    "\n",
    "The task has something in common with supervised learning: loss is optimized through the buffer (instead of Train dataset). But the distribution of states and actions in the buffer **is not stationary** and depends on the policy that generated it. It can even happen that the mean TD error across the buffer is very low but the performance is extremely poor (imagine the agent collecting data to the buffer always manages to avoid the ball).\n",
    "\n",
    "* Total timesteps and training time: It seems to be so huge, but actually it is normal for RL.\n",
    "\n",
    "* $\\epsilon$ decay shedule was taken from the original paper and is like traditional for epsilon-greedy policies. At the beginning of the training the agent's greedy policy is poor so many random actions should be taken.\n",
    "\n",
    "* Optimizer: In the original paper RMSProp was used (they did not have Adam in 2013) and it can work not worse than Adam. For us Adam was default and it worked.\n",
    "\n",
    "* lr: $10^{-3}$ would probably be too huge\n",
    "\n",
    "* batch size: This one can be very important: if it is too small the agent can fail to learn. Huge batch takes more time to process.\n",
    "\n",
    "* target network update frequency: has something in common with learning rate. Too frequent updates can lead to divergence. Too rare can lead to slow learning. For millions of total timesteps thousands of inner steps seem ok. One iteration of target network updating is an iteration of the (this time approximate) $\\gamma$-compression that stands behind Q-learning. The more inner steps it makes the more accurate is the compression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's have a closer look at this.\n",
    "\n",
    "If average episode score is below 200 using all 5 lives, then probably DQN has not converged fully. But anyway let's make a more complete record of an episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = make_env(clip_rewards=False)\n",
    "record = utils.play_and_log_episode(eval_env, agent)\n",
    "print('total reward for life:', np.sum(record['rewards']))\n",
    "for key in record:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.scatter(record['v_mc'], record['v_agent'])\n",
    "ax.plot(sorted(record['v_mc']), sorted(record['v_mc']),\n",
    "       'black', linestyle='--', label='x=y')\n",
    "\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "ax.set_title('State Value Estimates')\n",
    "ax.set_xlabel('Monte-Carlo')\n",
    "ax.set_ylabel('Agent')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat V_{Monte-Carlo}(s_t) = \\sum_{\\tau=0}^{episode~end} \\gamma^{\\tau-t}r_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a big bias? It's ok, anyway it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record sessions\n",
    "\n",
    "import gym.wrappers\n",
    "\n",
    "with gym.wrappers.Monitor(make_env(), directory=\"videos\", force=True) as env_monitor:\n",
    "    sessions = [evaluate(env_monitor, agent, n_games=n_lives, greedy=True) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_names[-1]))  # You can also try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus I (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Plot several (say 3) states with high and low spreads of Q estimate by actions i.e.\n",
    "$$\\max_a \\hat Q(s,a) - \\min_a \\hat Q(s,a)\\$$\n",
    "Please take those states from different episodes to make sure that the states are really different.\n",
    "\n",
    "What should high and low spread mean at least in the world of perfect Q-fucntions?\n",
    "\n",
    "Comment the states you like most.\n",
    "\n",
    "**2.** Plot several (say 3) states with high td-error and several states with high values of\n",
    "$$| \\hat V_{Monte-Carlo}(s) - \\hat V_{agent}(s)|,$$ \n",
    "$$\\hat V_{agent}(s)=\\max_a \\hat Q(s,a).$$ Please take those states from different episodes to make sure that the states are really different. From what part (i.e. beginning, middle, end) of an episode did these states come from?\n",
    "\n",
    "Comment the states you like most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import play_and_log_episode, img_by_obs\n",
    "\n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus II (1-5 pts). Get High Score!\n",
    "\n",
    "1 point to you for each 50 points of your agent. Truncated by 5 points. Starting with 50 points, **not** 50 + threshold.\n",
    "\n",
    "One way is to train for several days and use heavier hardware (why not actually).\n",
    "\n",
    "Another way is to apply modifications (see **Bonus III**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus III (2+ pts). Apply modifications to DQN.\n",
    "\n",
    "For inspiration see [Rainbow](https://arxiv.org/abs/1710.02298) - a version of q-learning that combines lots of them.\n",
    "\n",
    "Points for Bonus II and Bonus III fully stack. So if modified agent gets score 250+ you get 5 pts for Bonus II + points for modifications. If the final score is 40 then you get the points for modifications.\n",
    "\n",
    "\n",
    "Some modifications:\n",
    "* [Prioritized experience replay](https://arxiv.org/abs/1511.05952) (5 pts for your own implementation, 3 pts for using a ready one)\n",
    "* [double q-learning](https://arxiv.org/abs/1509.06461) (2 pts)\n",
    "* [dueling q-learning](https://arxiv.org/abs/1511.06581) (2 pts)\n",
    "* multi-step heuristics (see [Rainbow](https://arxiv.org/abs/1710.02298)) (3 pts)\n",
    "* [Noisy Nets](https://arxiv.org/abs/1706.10295) (3 pts)\n",
    "* [distributional RL](https://arxiv.org/abs/1707.06887)(distributional and distributed stand for different things here) (5 pts)\n",
    "* Other modifications (2+ pts depending on complexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus IV (4+ pts). Distributed RL.\n",
    "\n",
    "Solve the task in a distributed way. It can strongly speed up learning. See [article](https://arxiv.org/pdf/1602.01783.pdf) or some guides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As usual bonus points for all the tasks fully stack.**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
